### 1.èƒŒæ™¯æ„ä¹‰

ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰

æ¡ƒæ ‘ä½œä¸ºä¸€ç§é‡è¦çš„ç»æµä½œç‰©ï¼Œå¹¿æ³›ç§æ¤äºå…¨çƒå¤šä¸ªåœ°åŒºï¼Œå…¶æœå®ä¸ä»…å¯Œå«è¥å…»ï¼Œè€Œä¸”åœ¨å¸‚åœºä¸Šå…·æœ‰è¾ƒé«˜çš„ç»æµä»·å€¼ã€‚ç„¶è€Œï¼Œæ¡ƒæ ‘åœ¨ç”Ÿé•¿è¿‡ç¨‹ä¸­å®¹æ˜“å—åˆ°å¤šç§ç—…å®³çš„ä¾µè¢­ï¼Œä¸¥é‡å½±å“å…¶äº§é‡å’Œæœå®è´¨é‡ã€‚æ ¹æ®ç ”ç©¶ï¼Œä¸»è¦çš„æ¡ƒæ ‘ç—…å®³åŒ…æ‹¬ç»†èŒæ€§æ–‘ç‚¹ç—…ï¼ˆManchaBaterialï¼‰ã€çº¢é”ˆç—…ï¼ˆRoyaï¼‰å’Œæ¡ƒæ ‘è…çƒ‚ç—…ï¼ˆTaphrinaï¼‰ï¼Œè¿™äº›ç—…å®³ä¸ä»…ä¼šå¯¼è‡´æœå®è…çƒ‚ã€æ ‘ä½“æ¯èï¼Œè¿˜å¯èƒ½é€ æˆä¸¥é‡çš„ç»æµæŸå¤±ã€‚å› æ­¤ï¼ŒåŠæ—¶ã€å‡†ç¡®åœ°æ£€æµ‹å’Œè¯†åˆ«è¿™äº›ç—…å®³ï¼Œå¯¹äºæé«˜æ¡ƒæ ‘çš„äº§é‡å’Œè´¨é‡å…·æœ‰é‡è¦çš„ç°å®æ„ä¹‰ã€‚

è¿‘å¹´æ¥ï¼Œéšç€è®¡ç®—æœºè§†è§‰æŠ€æœ¯çš„è¿…çŒ›å‘å±•ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒè¯†åˆ«æ–¹æ³•é€æ¸æˆä¸ºå†œä¸šç—…å®³æ£€æµ‹çš„é‡è¦å·¥å…·ã€‚YOLOï¼ˆYou Only Look Onceï¼‰ç³»åˆ—æ¨¡å‹å› å…¶é«˜æ•ˆçš„å®æ—¶æ£€æµ‹èƒ½åŠ›ï¼Œå·²è¢«å¹¿æ³›åº”ç”¨äºå„ç§ç‰©ä½“æ£€æµ‹ä»»åŠ¡ã€‚ç‰¹åˆ«æ˜¯YOLOv11çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œç»“åˆäº†æ›´å…ˆè¿›çš„ç‰¹å¾æå–å’Œå¤„ç†æŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚çš„ç¯å¢ƒä¸­å®ç°æ›´é«˜çš„æ£€æµ‹ç²¾åº¦å’Œé€Ÿåº¦ã€‚å› æ­¤ï¼ŒåŸºäºæ”¹è¿›YOLOv11çš„æ¡ƒæ ‘ç—…å®³æ£€æµ‹ç³»ç»Ÿçš„æ„å»ºï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡ç—…å®³è¯†åˆ«çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œä¸ºæœå†œæä¾›åŠæ—¶çš„å†³ç­–æ”¯æŒã€‚

æœ¬ç ”ç©¶å°†åˆ©ç”¨åŒ…å«4000å¼ æ ‡æ³¨å›¾åƒçš„æ•°æ®é›†ï¼Œæ¶µç›–äº†ä¸‰ç§ä¸»è¦çš„æ¡ƒæ ‘ç—…å®³ç±»åˆ«ã€‚é€šè¿‡å¯¹æ•°æ®é›†çš„æ·±å…¥åˆ†æä¸å¤„ç†ï¼Œç»“åˆæ”¹è¿›çš„YOLOv11æ¨¡å‹ï¼Œæ—¨åœ¨å¼€å‘å‡ºä¸€å¥—é«˜æ•ˆçš„æ¡ƒæ ‘ç—…å®³æ£€æµ‹ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿä¸ä»…èƒ½å¤Ÿå®æ—¶ç›‘æµ‹æ¡ƒæ ‘çš„å¥åº·çŠ¶å†µï¼Œè¿˜èƒ½ä¸ºå†œä¸šç®¡ç†æä¾›ç§‘å­¦ä¾æ®ï¼Œä¿ƒè¿›å¯æŒç»­å†œä¸šçš„å‘å±•ã€‚é€šè¿‡æœ¬é¡¹ç›®çš„å®æ–½ï¼ŒæœŸæœ›èƒ½å¤Ÿä¸ºæ¡ƒæ ‘ç§æ¤è€…æä¾›æ›´ä¸ºç²¾å‡†çš„ç—…å®³æ£€æµ‹å·¥å…·ï¼Œé™ä½ç—…å®³æŸå¤±ï¼Œæé«˜ç»æµæ•ˆç›Šï¼Œä»è€Œæ¨åŠ¨æ¡ƒæ ‘äº§ä¸šçš„å¥åº·å‘å±•ã€‚

### 2.è§†é¢‘æ•ˆæœ

[2.1 è§†é¢‘æ•ˆæœ](https://www.bilibili.com/video/BV1iQkcYLEDL/)

### 3.å›¾ç‰‡æ•ˆæœ

![1.png](1.png)

![2.png](2.png)

![3.png](3.png)

##### [é¡¹ç›®æ¶‰åŠçš„æºç æ•°æ®æ¥æºé“¾æ¥](https://kdocs.cn/l/cszuIiCKVNis)**

æ³¨æ„ï¼šæœ¬é¡¹ç›®æä¾›è®­ç»ƒçš„æ•°æ®é›†å’Œè®­ç»ƒæ•™ç¨‹,ç”±äºç‰ˆæœ¬æŒç»­æ›´æ–°,æš‚ä¸æä¾›æƒé‡æ–‡ä»¶ï¼ˆbest.ptï¼‰,è¯·æŒ‰ç…§6.è®­ç»ƒæ•™ç¨‹è¿›è¡Œè®­ç»ƒåå®ç°ä¸Šå›¾æ¼”ç¤ºçš„æ•ˆæœã€‚

### 4.æ•°æ®é›†ä¿¡æ¯

##### 4.1 æœ¬é¡¹ç›®æ•°æ®é›†ç±»åˆ«æ•°ï¼†ç±»åˆ«å

nc: 3
names: ['ManchaBaterial', 'Roya', 'Taphrina']



è¯¥é¡¹ç›®ä¸ºã€å›¾åƒåˆ†å‰²ã€‘æ•°æ®é›†ï¼Œè¯·åœ¨ã€è®­ç»ƒæ•™ç¨‹å’ŒWebç«¯åŠ è½½æ¨¡å‹æ•™ç¨‹ï¼ˆç¬¬ä¸‰æ­¥ï¼‰ã€‘è¿™ä¸€æ­¥çš„æ—¶å€™æŒ‰ç…§ã€å›¾åƒåˆ†å‰²ã€‘éƒ¨åˆ†çš„æ•™ç¨‹æ¥è®­ç»ƒ

##### 4.2 æœ¬é¡¹ç›®æ•°æ®é›†ä¿¡æ¯ä»‹ç»

æœ¬é¡¹ç›®æ•°æ®é›†ä¿¡æ¯ä»‹ç»

æœ¬é¡¹ç›®æ—¨åœ¨å¼€å‘ä¸€ä¸ªæ”¹è¿›ç‰ˆçš„YOLOv11æ¡ƒæ ‘ç—…å®³æ£€æµ‹ç³»ç»Ÿï¼Œæ‰€ä½¿ç”¨çš„æ•°æ®é›†åä¸ºâ€œpeach-diseasesUSFX-â€ã€‚è¯¥æ•°æ®é›†ä¸“æ³¨äºæ¡ƒæ ‘ç—…å®³çš„è¯†åˆ«ä¸åˆ†ç±»ï¼Œæ¶µç›–äº†ä¸‰ç§ä¸»è¦çš„ç—…å®³ç±»å‹ï¼Œåˆ†åˆ«ä¸ºâ€œManchaBaterialâ€ï¼ˆç»†èŒæ–‘ç‚¹ç—…ï¼‰ã€â€œRoyaâ€ï¼ˆæ¡ƒæ ‘é”ˆç—…ï¼‰å’Œâ€œTaphrinaâ€ï¼ˆæ¡ƒæ ‘è…çƒ‚ç—…ï¼‰ã€‚è¿™äº›ç—…å®³åœ¨æ¡ƒæ ‘çš„ç”Ÿé•¿è¿‡ç¨‹ä¸­å¸¸å¸¸é€ æˆä¸¥é‡çš„ç»æµæŸå¤±ï¼Œå› æ­¤ï¼Œå‡†ç¡®çš„ç—…å®³æ£€æµ‹å¯¹äºæé«˜æ¡ƒæ ‘çš„äº§é‡å’Œè´¨é‡è‡³å…³é‡è¦ã€‚

æ•°æ®é›†ä¸­åŒ…å«äº†å¤§é‡çš„æ ‡æ³¨å›¾åƒï¼Œè¿™äº›å›¾åƒå‡ç»è¿‡ç²¾ç»†çš„æ ‡æ³¨ï¼Œä»¥ç¡®ä¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æœ‰æ•ˆçš„ç‰¹å¾ã€‚æ¯ä¸€ç±»ç—…å®³çš„æ ·æœ¬æ•°é‡å‡è¡¡ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹å¯¹ä¸åŒç—…å®³çš„è¯†åˆ«èƒ½åŠ›ã€‚æ•°æ®é›†ä¸­çš„å›¾åƒæ¥æºäºä¸åŒçš„ç”Ÿé•¿ç¯å¢ƒå’Œæ°”å€™æ¡ä»¶ï¼Œç¡®ä¿äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤šæ ·åŒ–çš„å®é™…åº”ç”¨åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ã€‚

åœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µï¼Œæˆ‘ä»¬å¯¹å›¾åƒè¿›è¡Œäº†æ ‡å‡†åŒ–å¤„ç†ï¼ŒåŒ…æ‹¬å°ºå¯¸è°ƒæ•´ã€é¢œè‰²å¢å¼ºå’Œå™ªå£°å»é™¤ç­‰ï¼Œä»¥æå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚æ­¤å¤–ï¼Œæ•°æ®é›†è¿˜åŒ…å«äº†ä¸€äº›å›¾åƒçš„å¢å¼ºç‰ˆæœ¬ï¼Œä»¥å¢åŠ æ ·æœ¬çš„å¤šæ ·æ€§ï¼Œè¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚é€šè¿‡ä½¿ç”¨è¯¥æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œæˆ‘ä»¬æœŸæœ›èƒ½å¤Ÿæ„å»ºä¸€ä¸ªé«˜æ•ˆã€å‡†ç¡®çš„æ¡ƒæ ‘ç—…å®³æ£€æµ‹ç³»ç»Ÿï¼Œä»è€Œä¸ºæœå†œæä¾›åŠæ—¶çš„ç—…å®³é¢„è­¦ï¼Œå¸®åŠ©ä»–ä»¬é‡‡å–æœ‰æ•ˆçš„é˜²æ²»æªæ–½ï¼Œæœ€ç»ˆå®ç°å†œä¸šç”Ÿäº§çš„å¯æŒç»­å‘å±•ã€‚

![4.png](4.png)

![5.png](5.png)

![6.png](6.png)

![7.png](7.png)

![8.png](8.png)

### 5.å…¨å¥—é¡¹ç›®ç¯å¢ƒéƒ¨ç½²è§†é¢‘æ•™ç¨‹ï¼ˆé›¶åŸºç¡€æ‰‹æŠŠæ‰‹æ•™å­¦ï¼‰

[5.1 æ‰€éœ€è½¯ä»¶PyCharmå’ŒAnacondaå®‰è£…æ•™ç¨‹ï¼ˆç¬¬ä¸€æ­¥ï¼‰](https://www.bilibili.com/video/BV1BoC1YCEKi/?spm_id_from=333.999.0.0&vd_source=bc9aec86d164b67a7004b996143742dc)




[5.2 å®‰è£…Pythonè™šæ‹Ÿç¯å¢ƒåˆ›å»ºå’Œä¾èµ–åº“å®‰è£…è§†é¢‘æ•™ç¨‹ï¼ˆç¬¬äºŒæ­¥ï¼‰](https://www.bilibili.com/video/BV1ZoC1YCEBw?spm_id_from=333.788.videopod.sections&vd_source=bc9aec86d164b67a7004b996143742dc)

### 6.æ”¹è¿›YOLOv11è®­ç»ƒæ•™ç¨‹å’ŒWeb_UIå‰ç«¯åŠ è½½æ¨¡å‹æ•™ç¨‹ï¼ˆé›¶åŸºç¡€æ‰‹æŠŠæ‰‹æ•™å­¦ï¼‰

[6.1 æ”¹è¿›YOLOv11è®­ç»ƒæ•™ç¨‹å’ŒWeb_UIå‰ç«¯åŠ è½½æ¨¡å‹æ•™ç¨‹ï¼ˆç¬¬ä¸‰æ­¥ï¼‰](https://www.bilibili.com/video/BV1BoC1YCEhR?spm_id_from=333.788.videopod.sections&vd_source=bc9aec86d164b67a7004b996143742dc)


æŒ‰ç…§ä¸Šé¢çš„è®­ç»ƒè§†é¢‘æ•™ç¨‹é“¾æ¥åŠ è½½é¡¹ç›®æä¾›çš„æ•°æ®é›†ï¼Œè¿è¡Œtrain.pyå³å¯å¼€å§‹è®­ç»ƒ
ï»¿


     Epoch   gpu_mem       box       obj       cls    labels  img_size
     1/200     20.8G   0.01576   0.01955  0.007536        22      1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [14:42<00:00,  1.04s/it]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [01:14<00:00,  2.87it/s]
                 all       3395      17314      0.994      0.957      0.0957      0.0843

     Epoch   gpu_mem       box       obj       cls    labels  img_size
     2/200     20.8G   0.01578   0.01923  0.007006        22      1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [14:44<00:00,  1.04s/it]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [01:12<00:00,  2.95it/s]
                 all       3395      17314      0.996      0.956      0.0957      0.0845

     Epoch   gpu_mem       box       obj       cls    labels  img_size
     3/200     20.8G   0.01561    0.0191  0.006895        27      1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [10:56<00:00,  1.29it/s]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 187/213 [00:52<00:00,  4.04it/s]
                 all       3395      17314      0.996      0.957      0.0957      0.0845




###### [é¡¹ç›®æ•°æ®é›†ä¸‹è½½é“¾æ¥](https://kdocs.cn/l/cszuIiCKVNis)

### 7.åŸå§‹YOLOv11ç®—æ³•è®²è§£

YOLOv11æ˜¯Ultralyticsæ¨å‡ºçš„YOLOç³»åˆ—æœ€æ–°ç‰ˆæœ¬ï¼Œä¸“ä¸ºå®ç°å°–ç«¯çš„ç‰©ä½“æ£€æµ‹è€Œè®¾è®¡ã€‚å…¶æ¶æ„å’Œè®­ç»ƒæ–¹æ³•ä¸Šè¿›è¡Œäº†é‡å¤§æ”¹è¿›ï¼Œä½¿ä¹‹ä¸ä»…å…·å¤‡å“è¶Šçš„å‡†ç¡®æ€§å’Œå¤„ç†é€Ÿåº¦ï¼Œè¿˜åœ¨è®¡ç®—æ•ˆç‡ä¸Šå®ç°äº†ä¸€åœºé©å‘½ã€‚å¾—ç›Šäºå…¶æ”¹è¿›çš„ä¸»å¹²å’Œé¢ˆéƒ¨æ¶æ„ï¼ŒYOLOv11åœ¨ç‰¹å¾æå–å’Œå¤„ç†å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°æ›´åŠ å‡ºè‰²ã€‚åœ¨2024å¹´9æœˆ27æ—¥ï¼ŒUltralyticsé€šè¿‡é•¿è¾¾ä¹å°æ—¶çš„åœ¨çº¿ç›´æ’­å‘å¸ƒè¿™ä¸€æ–°ä½œï¼Œå±•ç¤ºäº†å…¶åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„é©æ–°ã€‚

YOLOv11é€šè¿‡ç²¾ç»†çš„æ¶æ„è®¾è®¡å’Œä¼˜åŒ–è®­ç»ƒæµç¨‹ï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ï¼Œç¼©å‡äº†å‚æ•°é‡ï¼Œä¸YOLOv8mç›¸æ¯”å‡å°‘äº†22%çš„å‚æ•°ï¼Œä½¿å…¶åœ¨COCOæ•°æ®é›†ä¸Šçš„å¹³å‡å‡†ç¡®åº¦ï¼ˆmAPï¼‰æœ‰æ‰€æå‡ã€‚è¿™ç§æ•ˆç‡çš„æé«˜ä½¿YOLOv11éå¸¸é€‚åˆéƒ¨ç½²åœ¨å„ç§ç¡¬ä»¶ç¯å¢ƒä¸­ï¼ŒåŒ…æ‹¬è¾¹ç¼˜è®¾å¤‡ã€äº‘è®¡ç®—å¹³å°ä»¥åŠæ”¯æŒNVIDIA GPUçš„ç³»ç»Ÿï¼Œç¡®ä¿åœ¨çµæ´»æ€§ä¸Šçš„ä¼˜åŠ¿ã€‚

è¯¥æ¨¡å‹æ”¯æŒå¹¿æ³›çš„ä»»åŠ¡ï¼Œä»å¯¹è±¡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²åˆ°å›¾åƒåˆ†ç±»ã€å§¿æ€ä¼°è®¡å’Œå®šå‘å¯¹è±¡æ£€æµ‹ï¼ˆOBBï¼‰ï¼Œå‡ ä¹è¦†ç›–äº†è®¡ç®—æœºè§†è§‰çš„æ‰€æœ‰ä¸»è¦æŒ‘æˆ˜ã€‚å…¶åˆ›æ–°çš„C3k2å’ŒC2PSAæ¨¡å—æå‡äº†ç½‘ç»œæ·±åº¦å’Œæ³¨æ„åŠ›æœºåˆ¶çš„åº”ç”¨ï¼Œæé«˜äº†ç‰¹å¾æå–çš„æ•ˆç‡å’Œæ•ˆæœã€‚åŒæ—¶ï¼ŒYOLOv11çš„æ”¹è¿›ç½‘ç»œç»“æ„ä¹Ÿä½¿ä¹‹åœ¨å¤æ‚è§†è§‰ä»»åŠ¡ä¸Šå¾—ä»¥ä»å®¹åº”å¯¹ï¼Œæˆä¸ºå„ç±»è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„å¤šåŠŸèƒ½é€‰æ‹©ã€‚è¿™äº›ç‰¹æ€§ä»¤YOLOv11åœ¨å®æ–½å®æ—¶ç‰©ä½“æ£€æµ‹çš„å„ä¸ªé¢†åŸŸä¸­è¡¨ç°å‡ºä¼—ã€‚
* * *

2024å¹´9æœˆ27æ—¥ï¼ŒUltralyticsåœ¨çº¿ç›´æ’­é•¿è¾¾ä¹å°æ—¶ï¼Œä¸ºYOLO11å¬å¼€â€œå‘å¸ƒä¼šâ€

YOLO11 æ˜¯ Ultralytics YOLO ç³»åˆ—å®æ—¶ç‰©ä½“æ£€æµ‹å™¨çš„æœ€æ–°ç‰ˆæœ¬ï¼Œå®ƒä»¥å°–ç«¯çš„å‡†ç¡®æ€§ã€é€Ÿåº¦å’Œæ•ˆç‡é‡æ–°å®šä¹‰äº†å¯èƒ½æ€§ã€‚åœ¨ä¹‹å‰ YOLO
ç‰ˆæœ¬çš„æ˜¾è‘—è¿›æ­¥çš„åŸºç¡€ä¸Šï¼ŒYOLO11 åœ¨æ¶æ„å’Œè®­ç»ƒæ–¹æ³•æ–¹é¢è¿›è¡Œäº†é‡å¤§æ”¹è¿›ï¼Œä½¿å…¶æˆä¸ºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„å¤šåŠŸèƒ½é€‰æ‹©ã€‚

![](https://i-blog.csdnimg.cn/direct/a4e1a178833746249720ccee1c82a58b.png)

##### YOLO11ä¸»è¦ç‰¹ç‚¹ï¼š

  * å¢å¼ºçš„ç‰¹å¾æå–ï¼šYOLO11 é‡‡ç”¨äº†æ”¹è¿›çš„ä¸»å¹²å’Œé¢ˆéƒ¨æ¶æ„ï¼Œå¢å¼ºäº†ç‰¹å¾æå–èƒ½åŠ›ï¼Œå¯å®ç°æ›´ç²¾ç¡®çš„å¯¹è±¡æ£€æµ‹å’Œå¤æ‚ä»»åŠ¡æ€§èƒ½ã€‚
  * é’ˆå¯¹æ•ˆç‡å’Œé€Ÿåº¦è¿›è¡Œäº†ä¼˜åŒ–ï¼šYOLO11 å¼•å…¥äº†å®Œå–„çš„æ¶æ„è®¾è®¡å’Œä¼˜åŒ–çš„è®­ç»ƒæµç¨‹ï¼Œå¯æä¾›æ›´å¿«çš„å¤„ç†é€Ÿåº¦ï¼Œå¹¶åœ¨å‡†ç¡®åº¦å’Œæ€§èƒ½ä¹‹é—´ä¿æŒæœ€ä½³å¹³è¡¡ã€‚
  * æ›´å°‘çš„å‚æ•°ï¼Œæ›´é«˜çš„å‡†ç¡®åº¦ï¼šå€ŸåŠ©æ¨¡å‹è®¾è®¡çš„è¿›æ­¥ï¼ŒYOLO11m åœ¨ COCO æ•°æ®é›†ä¸Šå®ç°äº†æ›´é«˜çš„å¹³å‡å‡†ç¡®åº¦ (mAP)ï¼ŒåŒæ—¶ä½¿ç”¨çš„å‚æ•°æ¯” YOLOv8m å°‘ 22%ï¼Œä»è€Œæé«˜äº†è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶åˆä¸å½±å“å‡†ç¡®åº¦ã€‚
  * è·¨ç¯å¢ƒçš„é€‚åº”æ€§ï¼šYOLO11 å¯ä»¥æ— ç¼éƒ¨ç½²åœ¨å„ç§ç¯å¢ƒä¸­ï¼ŒåŒ…æ‹¬è¾¹ç¼˜è®¾å¤‡ã€äº‘å¹³å°å’Œæ”¯æŒ NVIDIA GPU çš„ç³»ç»Ÿï¼Œä»è€Œç¡®ä¿æœ€å¤§çš„çµæ´»æ€§ã€‚
  * æ”¯æŒçš„ä»»åŠ¡èŒƒå›´å¹¿æ³›ï¼šæ— è®ºæ˜¯å¯¹è±¡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€å›¾åƒåˆ†ç±»ã€å§¿åŠ¿ä¼°è®¡è¿˜æ˜¯å®šå‘å¯¹è±¡æ£€æµ‹ (OBB)ï¼ŒYOLO11 éƒ½æ—¨åœ¨æ»¡è¶³å„ç§è®¡ç®—æœºè§†è§‰æŒ‘æˆ˜ã€‚

##### æ”¯æŒçš„ä»»åŠ¡å’Œæ¨¡å¼

YOLO11 ä»¥ YOLOv8 ä¸­å¼•å…¥çš„å¤šåŠŸèƒ½æ¨¡å‹ç³»åˆ—ä¸ºåŸºç¡€ï¼Œä¸ºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡æä¾›å¢å¼ºçš„æ”¯æŒï¼š

Model| Filenames| Task| Inference| Validation| Training| Export  
---|---|---|---|---|---|---  
YOLO11| yolol11n.pt, yolol11s.pt, yolol11m.pt, yolol11x.pt| Detection| âœ…| âœ…|
âœ…| âœ…  
YOLO11-seg| yolol11n-seg.pt, yolol11s-seg.pt, yolol11m-seg.pt,
yolol11x-seg.pt| Instance Segmentation| âœ…| âœ…| âœ…| âœ…  
YOLO11-pose| yolol11n-pose.pt, yolol11s-pose.pt, yolol11m-pose.pt,
yolol11x-pose.pt| Pose/Keypoints| âœ…| âœ…| âœ…| âœ…  
YOLO11-obb| yolol11n-obb.pt, yolol11s-obb.pt, yolol11m-obb.pt,
yolol11x-obb.pt| Oriented Detection| âœ…| âœ…| âœ…| âœ…  
YOLO11-cls| yolol11n-cls.pt, yolol11s-cls.pt, yolol11m-cls.pt,
yolol11x-cls.pt| Classification| âœ…| âœ…| âœ…| âœ…  
  
##### ç®€å•çš„ YOLO11 è®­ç»ƒå’Œæ¨ç†ç¤ºä¾‹

ä»¥ä¸‹ç¤ºä¾‹é€‚ç”¨äºç”¨äºå¯¹è±¡æ£€æµ‹çš„ YOLO11 Detect æ¨¡å‹ã€‚

    
    
    from ultralytics import YOLO
    
    # Load a model
    model = YOLO("yolo11n.pt")
    
    # Train the model
    train_results = model.train(
        data="coco8.yaml",  # path to dataset YAML
        epochs=100,  # number of training epochs
        imgsz=640,  # training image size
        device="cpu",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu
    )
    
    # Evaluate model performance on the validation set
    metrics = model.val()
    
    # Perform object detection on an image
    results = model("path/to/image.jpg")
    results[0].show()
    
    # Export the model to ONNX format
    path = model.export(format="onnx")  # return path to exported model

##### æ”¯æŒéƒ¨ç½²äºè¾¹ç¼˜è®¾å¤‡

YOLO11 ä¸“ä¸ºé€‚åº”å„ç§ç¯å¢ƒè€Œè®¾è®¡ï¼ŒåŒ…æ‹¬è¾¹ç¼˜è®¾å¤‡ã€‚å…¶ä¼˜åŒ–çš„æ¶æ„å’Œé«˜æ•ˆçš„å¤„ç†èƒ½åŠ›ä½¿å…¶é€‚åˆéƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ã€äº‘å¹³å°å’Œæ”¯æŒ NVIDIA GPU
çš„ç³»ç»Ÿä¸Šã€‚è¿™ç§çµæ´»æ€§ç¡®ä¿ YOLO11 å¯ç”¨äºå„ç§åº”ç”¨ï¼Œä»ç§»åŠ¨è®¾å¤‡ä¸Šçš„å®æ—¶æ£€æµ‹åˆ°äº‘ç¯å¢ƒä¸­çš„å¤æ‚åˆ†å‰²ä»»åŠ¡ã€‚æœ‰å…³éƒ¨ç½²é€‰é¡¹çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…å¯¼å‡ºæ–‡æ¡£ã€‚

##### YOLOv11 yamlæ–‡ä»¶

    
    
    # Ultralytics YOLO ğŸš€, AGPL-3.0 license
    # YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
    
    # Parameters
    nc: 80 # number of classes
    scales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'
      # [depth, width, max_channels]
      n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs
      s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs
      m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs
      l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs
      x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs
    
    # YOLO11n backbone
    backbone:
      # [from, repeats, module, args]
      - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
      - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
      - [-1, 2, C3k2, [256, False, 0.25]]
      - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
      - [-1, 2, C3k2, [512, False, 0.25]]
      - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
      - [-1, 2, C3k2, [512, True]]
      - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
      - [-1, 2, C3k2, [1024, True]]
      - [-1, 1, SPPF, [1024, 5]] # 9
      - [-1, 2, C2PSA, [1024]] # 10
    
    # YOLO11n head
    head:
      - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
      - [[-1, 6], 1, Concat, [1]] # cat backbone P4
      - [-1, 2, C3k2, [512, False]] # 13
    
      - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
      - [[-1, 4], 1, Concat, [1]] # cat backbone P3
      - [-1, 2, C3k2, [256, False]] # 16 (P3/8-small)
    
      - [-1, 1, Conv, [256, 3, 2]]
      - [[-1, 13], 1, Concat, [1]] # cat head P4
      - [-1, 2, C3k2, [512, False]] # 19 (P4/16-medium)
    
      - [-1, 1, Conv, [512, 3, 2]]
      - [[-1, 10], 1, Concat, [1]] # cat head P5
      - [-1, 2, C3k2, [1024, True]] # 22 (P5/32-large)
    
      - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)
    

**YOLO11å’ŒYOLOv8 yamlæ–‡ä»¶çš„åŒºåˆ«**

![](https://i-blog.csdnimg.cn/direct/a8f3766a015c4ad2a49411ab710b3477.png)

##### æ”¹è¿›æ¨¡å—ä»£ç 

  * C3k2 

    
    
    class C3k2(C2f):
        """Faster Implementation of CSP Bottleneck with 2 convolutions."""
    
        def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):
            """Initializes the C3k2 module, a faster CSP Bottleneck with 2 convolutions and optional C3k blocks."""
            super().__init__(c1, c2, n, shortcut, g, e)
            self.m = nn.ModuleList(
                C3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g) for _ in range(n)
            )

C3k2ï¼Œå®ƒæ˜¯å…·æœ‰ä¸¤ä¸ªå·ç§¯çš„CSPï¼ˆPartial Cross Stageï¼‰ç“¶é¢ˆæ¶æ„çš„æ›´å¿«å®ç°ã€‚

**ç±»ç»§æ‰¿ï¼š**

  * `C3k2`ç»§æ‰¿è‡ªç±»`C2f`ã€‚è¿™è¡¨æ˜`C2f`å¾ˆå¯èƒ½å®ç°äº†ç»è¿‡ä¿®æ”¹çš„åŸºæœ¬CSPç»“æ„ï¼Œè€Œ`C3k2`è¿›ä¸€æ­¥ä¼˜åŒ–æˆ–ä¿®æ”¹äº†æ­¤ç»“æ„ã€‚

**æ„é€ å‡½æ•°ï¼ˆ`__init__`ï¼‰ï¼š**

  * `c1`ï¼šè¾“å…¥é€šé“ã€‚

  * `c2`ï¼šè¾“å‡ºé€šé“ã€‚

  * `n`ï¼šç“¶é¢ˆå±‚æ•°ï¼ˆé»˜è®¤ä¸º1ï¼‰ã€‚

  * `c3k`ï¼šä¸€ä¸ªå¸ƒå°”æ ‡å¿—ï¼Œç¡®å®šæ˜¯å¦ä½¿ç”¨`C3k`å—æˆ–å¸¸è§„`Bottleneck`å—ã€‚

  * `e`ï¼šæ‰©å±•æ¯”ç‡ï¼Œæ§åˆ¶éšè—å±‚çš„å®½åº¦ï¼ˆé»˜è®¤ä¸º0.5ï¼‰ã€‚

  * `g`ï¼šåˆ†ç»„å·ç§¯çš„ç»„å½’ä¸€åŒ–å‚æ•°æˆ–ç»„æ•°ï¼ˆé»˜è®¤å€¼ä¸º 1ï¼‰ã€‚

  * `shortcut`ï¼šä¸€ä¸ªå¸ƒå°”å€¼ï¼Œç”¨äºç¡®å®šæ˜¯å¦åœ¨ç½‘ç»œä¸­åŒ…å«å¿«æ·æ–¹å¼è¿æ¥ï¼ˆé»˜è®¤å€¼ä¸º `True`ï¼‰ã€‚

**åˆå§‹åŒ–ï¼š**

  * `super().__init__(c1, c2, n, short-cut, g, e)` è°ƒç”¨çˆ¶ç±» `C2f` çš„æ„é€ å‡½æ•°ï¼Œåˆå§‹åŒ–æ ‡å‡† CSP ç»„ä»¶ï¼Œå¦‚é€šé“æ•°ã€å¿«æ·æ–¹å¼ã€ç»„ç­‰ã€‚

**æ¨¡å—åˆ—è¡¨ï¼ˆ`self.m`ï¼‰ï¼š**

  * `nn.ModuleList` å­˜å‚¨ `C3k` æˆ– `Bottleneck` æ¨¡å—ï¼Œå…·ä½“å–å†³äº `c3k` çš„å€¼ã€‚

  * å¦‚æœ `c3k` ä¸º `True`ï¼Œå®ƒä¼šåˆå§‹åŒ– `C3k` æ¨¡å—ã€‚`C3k` æ¨¡å—æ¥æ”¶ä»¥ä¸‹å‚æ•°ï¼š

  * `self.c`ï¼šé€šé“æ•°ï¼ˆæºè‡ª `C2f`ï¼‰ã€‚

  * `2`ï¼šè¿™è¡¨ç¤ºåœ¨ `C3k` å—å†…ä½¿ç”¨äº†ä¸¤ä¸ªå·ç§¯å±‚ã€‚

  * `shortcut` å’Œ `g`ï¼šä» `C3k2` æ„é€ å‡½æ•°ä¼ é€’ã€‚

  * å¦‚æœ `c3k` ä¸º `False`ï¼Œåˆ™åˆå§‹åŒ–æ ‡å‡† `Bottleneck` æ¨¡å—ã€‚

`for _ in range(n)` è¡¨ç¤ºå°†åˆ›å»º `n` ä¸ªè¿™æ ·çš„å—ã€‚

**æ€»ç»“ï¼š**

  * `C3k2` å®ç°äº† CSP ç“¶é¢ˆæ¶æ„ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨è‡ªå®šä¹‰ `C3k` å—ï¼ˆå…·æœ‰ä¸¤ä¸ªå·ç§¯ï¼‰æˆ–æ ‡å‡† `Bottleneck` å—ï¼Œå…·ä½“å–å†³äº `c3k` æ ‡å¿—ã€‚

  * C2PSA

    
    
    class C2PSA(nn.Module):
        """
        C2PSA module with attention mechanism for enhanced feature extraction and processing.
    
        This module implements a convolutional block with attention mechanisms to enhance feature extraction and processing
        capabilities. It includes a series of PSABlock modules for self-attention and feed-forward operations.
    
        Attributes:
            c (int): Number of hidden channels.
            cv1 (Conv): 1x1 convolution layer to reduce the number of input channels to 2*c.
            cv2 (Conv): 1x1 convolution layer to reduce the number of output channels to c.
            m (nn.Sequential): Sequential container of PSABlock modules for attention and feed-forward operations.
    
        Methods:
            forward: Performs a forward pass through the C2PSA module, applying attention and feed-forward operations.
    
        Notes:
            This module essentially is the same as PSA module, but refactored to allow stacking more PSABlock modules.
    
        Examples:
            >>> c2psa = C2PSA(c1=256, c2=256, n=3, e=0.5)
            >>> input_tensor = torch.randn(1, 256, 64, 64)
            >>> output_tensor = c2psa(input_tensor)
        """
    
        def __init__(self, c1, c2, n=1, e=0.5):
            """Initializes the C2PSA module with specified input/output channels, number of layers, and expansion ratio."""
            super().__init__()
            assert c1 == c2
            self.c = int(c1 * e)
            self.cv1 = Conv(c1, 2 * self.c, 1, 1)
            self.cv2 = Conv(2 * self.c, c1, 1)
    
            self.m = nn.Sequential(*(PSABlock(self.c, attn_ratio=0.5, num_heads=self.c // 64) for _ in range(n)))
    
        def forward(self, x):
            """Processes the input tensor 'x' through a series of PSA blocks and returns the transformed tensor."""
            a, b = self.cv1(x).split((self.c, self.c), dim=1)
            b = self.m(b)
            return self.cv2(torch.cat((a, b), 1))

`C2PSA` æ¨¡å—æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰ç¥ç»ç½‘ç»œå±‚ï¼Œå¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºå¢å¼ºç‰¹å¾æå–å’Œå¤„ç†ã€‚

**ç±»æ¦‚è¿°**

  * **ç›®çš„ï¼š**

  * `C2PSA` æ¨¡å—å¼•å…¥äº†ä¸€ä¸ªå·ç§¯å—ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥æ”¹è¿›ç‰¹å¾æå–å’Œå¤„ç†ã€‚

  * å®ƒä½¿ç”¨ä¸€ç³»åˆ— `PSABlock` æ¨¡å—ï¼Œè¿™äº›æ¨¡å—å¯èƒ½ä»£è¡¨æŸç§å½¢å¼çš„ä½ç½®è‡ªæ³¨æ„åŠ› (PSA)ï¼Œå¹¶ä¸”è¯¥æ¶æ„æ—¨åœ¨å…è®¸å †å å¤šä¸ª `PSABlock` å±‚ã€‚

**æ„é€ å‡½æ•°ï¼ˆ`__init__`ï¼‰ï¼š**

  * **å‚æ•°ï¼š**

  * `c1`ï¼šè¾“å…¥é€šé“ï¼ˆå¿…é¡»ç­‰äº `c2`ï¼‰ã€‚

  * `c2`ï¼šè¾“å‡ºé€šé“ï¼ˆå¿…é¡»ç­‰äº `c1`ï¼‰ã€‚

  * `n`ï¼šè¦å †å çš„ `PSABlock` æ¨¡å—æ•°é‡ï¼ˆé»˜è®¤å€¼ä¸º 1ï¼‰ã€‚

  * `e`ï¼šæ‰©å±•æ¯”ç‡ï¼Œç”¨äºè®¡ç®—éšè—é€šé“çš„æ•°é‡ï¼ˆé»˜è®¤å€¼ä¸º 0.5ï¼‰ã€‚

  * **å±æ€§ï¼š**

  * `self.c`ï¼šéšè—é€šé“æ•°ï¼Œè®¡ç®—ä¸º `int(c1 * e)`ã€‚

  * `self.cv1`ï¼šä¸€ä¸ª `1x1` å·ç§¯ï¼Œå°†è¾“å…¥é€šé“æ•°ä» `c1` å‡å°‘åˆ° `2 * self.c`ã€‚è¿™ä¸ºå°†è¾“å…¥åˆ†æˆä¸¤éƒ¨åˆ†åšå¥½å‡†å¤‡ã€‚

  * `self.cv2`ï¼šå¦ä¸€ä¸ª `1x1` å·ç§¯ï¼Œå¤„ç†åå°†é€šé“ç»´åº¦æ¢å¤å› `c1`ã€‚

  * `self.m`ï¼šä¸€ç³»åˆ— `PSABlock` æ¨¡å—ã€‚æ¯ä¸ª `PSABlock` æ¥æ”¶ `self.c` é€šé“ï¼Œæ³¨æ„å¤´çš„æ•°é‡ä¸º `self.c // 64`ã€‚æ¯ä¸ªå—åº”ç”¨æ³¨æ„å’Œå‰é¦ˆæ“ä½œã€‚

**å‰å‘æ–¹æ³•ï¼š**

  * **è¾“å…¥ï¼š**

  * `x`ï¼Œè¾“å…¥å¼ é‡ã€‚

  * **æ“ä½œï¼š**

  1. `self.cv1(x)` åº”ç”¨ `1x1` å·ç§¯ï¼Œå°†è¾“å…¥é€šé“å¤§å°ä» `c1` å‡å°åˆ° `2 * self.c`ã€‚

  2. ç”Ÿæˆçš„å¼ é‡æ²¿é€šé“ç»´åº¦åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œ`a` å’Œ `b`ã€‚

  * `a`ï¼šç¬¬ä¸€ä¸ª `self.c` é€šé“ã€‚

  * `b`ï¼šå‰©ä½™çš„ `self.c` é€šé“ã€‚

  1. `b` é€šè¿‡é¡ºåºå®¹å™¨ `self.m`ï¼Œå®ƒæ˜¯ `PSABlock` æ¨¡å—çš„å †æ ˆã€‚è¿™éƒ¨åˆ†ç»è¿‡åŸºäºæ³¨æ„çš„å¤„ç†ã€‚

  2. å¤„ç†åçš„å¼ é‡ `b` ä¸ `a` è¿æ¥ã€‚

  3. `self.cv2` åº”ç”¨ `1x1` å·ç§¯ï¼Œå°†é€šé“å¤§å°æ¢å¤ä¸º `c1`ã€‚

  * **è¾“å‡ºï¼š**

  * åº”ç”¨æ³¨æ„å’Œå·ç§¯æ“ä½œåçš„å˜æ¢åçš„å¼ é‡ã€‚

**æ€»ç»“ï¼š**

  * **C2PSA** æ˜¯ä¸€ä¸ªå¢å¼ºå‹å·ç§¯æ¨¡å—ï¼Œå®ƒé€šè¿‡å †å çš„ `PSABlock` æ¨¡å—åº”ç”¨ä½ç½®è‡ªæ³¨æ„åŠ›ã€‚å®ƒæ‹†åˆ†è¾“å…¥å¼ é‡ï¼Œå°†æ³¨æ„åŠ›åº”ç”¨äºå…¶ä¸­ä¸€éƒ¨åˆ†ï¼Œç„¶åé‡æ–°ç»„åˆå¹¶é€šè¿‡æœ€ç»ˆå·ç§¯å¯¹å…¶è¿›è¡Œå¤„ç†ã€‚æ­¤ç»“æ„æœ‰åŠ©äºä»è¾“å…¥æ•°æ®ä¸­æå–å¤æ‚ç‰¹å¾ã€‚

##### ç½‘ç»œç»“æ„

![](https://i-blog.csdnimg.cn/direct/761af09befeb45adafae36b679424b26.png)

![](https://i-blog.csdnimg.cn/direct/45e481e295ad458fa7fe4c252fbd5d83.png)




### 8.200+ç§å…¨å¥—æ”¹è¿›YOLOV11åˆ›æ–°ç‚¹åŸç†è®²è§£

#### 8.1 200+ç§å…¨å¥—æ”¹è¿›YOLOV11åˆ›æ–°ç‚¹åŸç†è®²è§£å¤§å…¨

ç”±äºç¯‡å¹…é™åˆ¶ï¼Œæ¯ä¸ªåˆ›æ–°ç‚¹çš„å…·ä½“åŸç†è®²è§£å°±ä¸å…¨éƒ¨å±•å¼€ï¼Œå…·ä½“è§ä¸‹åˆ—ç½‘å€ä¸­çš„æ”¹è¿›æ¨¡å—å¯¹åº”é¡¹ç›®çš„æŠ€æœ¯åŸç†åšå®¢ç½‘å€ã€Blogã€‘ï¼ˆåˆ›æ–°ç‚¹å‡ä¸ºæ¨¡å—åŒ–æ­å»ºï¼ŒåŸç†é€‚é…YOLOv5~YOLOv11ç­‰å„ç§ç‰ˆæœ¬ï¼‰

[æ”¹è¿›æ¨¡å—æŠ€æœ¯åŸç†åšå®¢ã€Blogã€‘ç½‘å€é“¾æ¥](https://gitee.com/qunmasj/good)

![9.png](9.png)

#### 8.2 ç²¾é€‰éƒ¨åˆ†æ”¹è¿›YOLOV11åˆ›æ–°ç‚¹åŸç†è®²è§£

###### è¿™é‡ŒèŠ‚é€‰éƒ¨åˆ†æ”¹è¿›åˆ›æ–°ç‚¹å±•å¼€åŸç†è®²è§£(å®Œæ•´çš„æ”¹è¿›åŸç†è§ä¸Šå›¾å’Œ[æ”¹è¿›æ¨¡å—æŠ€æœ¯åŸç†åšå®¢é“¾æ¥](https://gitee.com/qunmasj/good)ã€å¦‚æœæ­¤å°èŠ‚çš„å›¾åŠ è½½å¤±è´¥å¯ä»¥é€šè¿‡CSDNæˆ–è€…Githubæœç´¢è¯¥åšå®¢çš„æ ‡é¢˜è®¿é—®åŸå§‹åšå®¢ï¼ŒåŸå§‹åšå®¢å›¾ç‰‡æ˜¾ç¤ºæ­£å¸¸ã€‘
ï»¿
### å¯æ‰©å¼ æ®‹å·®ï¼ˆDWRï¼‰æ³¨æ„åŠ›æ¨¡å—
å½“å‰çš„è®¸å¤šå·¥ä½œç›´æ¥é‡‡ç”¨å¤šé€Ÿç‡æ·±åº¦æ‰©å¼ å·ç§¯ä»ä¸€ä¸ªè¾“å…¥ç‰¹å¾å›¾ä¸­åŒæ—¶æ•è·å¤šå°ºåº¦ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæé«˜å®æ—¶è¯­ä¹‰åˆ†å‰²çš„ç‰¹å¾æå–æ•ˆç‡ã€‚ ç„¶è€Œï¼Œè¿™ç§è®¾è®¡å¯èƒ½ä¼šå› ä¸ºç»“æ„å’Œè¶…å‚æ•°çš„ä¸åˆç†è€Œå¯¼è‡´å¤šå°ºåº¦ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è®¿é—®å›°éš¾ã€‚ ä¸ºäº†é™ä½ç»˜åˆ¶å¤šå°ºåº¦ä¸Šä¸‹æ–‡ä¿¡æ¯çš„éš¾åº¦ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„å¤šå°ºåº¦ç‰¹å¾æå–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ†è§£äº†åŸå§‹çš„å•æ­¥ç‰¹å¾æå–æ–¹æ³•æ–¹æ³•åˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼ŒåŒºåŸŸæ®‹å·®-è¯­ä¹‰æ®‹å·®ã€‚ åœ¨è¯¥æ–¹æ³•ä¸­ï¼Œå¤šé€Ÿç‡æ·±åº¦æ‰©å¼ å·ç§¯åœ¨ç‰¹å¾æå–ä¸­å‘æŒ¥æ›´ç®€å•çš„ä½œç”¨ï¼šæ ¹æ®ç¬¬ä¸€æ­¥æä¾›çš„æ¯ä¸ªç®€æ˜åŒºåŸŸå½¢å¼ç‰¹å¾å›¾ï¼Œåœ¨ç¬¬äºŒæ­¥ä¸­ä½¿ç”¨ä¸€ä¸ªæ‰€éœ€çš„æ„Ÿå—é‡æ‰§è¡Œç®€å•çš„åŸºäºè¯­ä¹‰çš„å½¢æ€è¿‡æ»¤ ä¸€æ­¥ï¼Œæé«˜ä»–ä»¬çš„æ•ˆç‡ã€‚ æ­¤å¤–ï¼Œæ‰©å¼ ç‡å’Œæ‰©å¼ å·ç§¯çš„å®¹é‡æ¯ä¸ªç½‘ç»œé˜¶æ®µéƒ½ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥å……åˆ†åˆ©ç”¨æ‰€æœ‰å¯ä»¥å®ç°çš„åŒºåŸŸå½¢å¼çš„ç‰¹å¾å›¾ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬åˆ†åˆ«ä¸ºé«˜å±‚å’Œä½å±‚ç½‘ç»œè®¾è®¡äº†ä¸€ç§æ–°é¢–çš„æ‰©å¼ å¼æ®‹å·®ï¼ˆDWRï¼‰æ¨¡å—å’Œç®€å•å€’ç½®æ®‹å·®ï¼ˆSIRï¼‰æ¨¡å—ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/6e648e3e6f484dc3a30c2b2edf852572.png)

é¦–å…ˆï¼Œè¯¥åšå®¢å¼•å…¥äº†ä¸€ä¸ªDilation-wise Residualï¼ˆDWRï¼‰æ¨¡å—ï¼Œç”¨äºæå–ç½‘ç»œé«˜å±‚çš„ç‰¹å¾ï¼Œå¦‚å›¾2aæ‰€ç¤ºã€‚å¤šåˆ†æ”¯ç»“æ„ç”¨äºæ‰©å±•æ„Ÿå—é‡ï¼Œå…¶ä¸­æ¯ä¸ªåˆ†æ”¯é‡‡ç”¨ä¸åŒç©ºæ´ç‡çš„ç©ºæ´æ·±åº¦å·ç§¯ã€‚
ç„¶åï¼Œä¸“é—¨è®¾è®¡äº†ä¸€ä¸ªSimple Inverted Residualï¼ˆSIRï¼‰æ¨¡å—æ¥æå–ç½‘ç»œä½å±‚çš„ç‰¹å¾ï¼Œå¦‚å›¾2bæ‰€ç¤ºã€‚è¯¥æ¨¡å—ä»…å…·æœ‰3Ã—3çš„å¾®å°æ„Ÿå—é‡ï¼Œä½†ä½¿ç”¨inverted bottleneckå¼ç»“æ„æ¥æ‰©å±•é€šé“æ•°é‡ï¼Œç¡®ä¿æ›´å¼ºçš„ç‰¹å¾æå–èƒ½åŠ›ã€‚
æœ€åï¼ŒåŸºäºDWRå’ŒSIRæ¨¡å—ï¼Œæ„å»ºäº†ä¸€ä¸ªç¼–ç å™¨-è§£ç å™¨é£æ ¼çš„ç½‘ç»œDWRSegï¼Œå…¶ä¸­è§£ç å™¨é‡‡ç”¨äº†ç®€å•çš„ç±»ä¼¼FCNçš„ç»“æ„ã€‚è§£ç å™¨ä½¿ç”¨æ¥è‡ªæœ€åä¸¤ä¸ªé˜¶æ®µçš„å¼ºè¯­ä¹‰ä¿¡æ¯ç›´æ¥å¯¹ç‰¹å¾å›¾è¿›è¡Œä¸Šé‡‡æ ·ï¼Œç„¶åå°†å®ƒä»¬ä¸æ¥è‡ªè¾ƒä½é˜¶æ®µçš„ç‰¹å¾å›¾ï¼ˆåŒ…å«ä¸°å¯Œçš„è¯¦ç»†ä¿¡æ¯ï¼‰æ‹¼æ¥èµ·æ¥ï¼Œä»¥è¿›è¡Œæœ€ç»ˆé¢„æµ‹ã€‚
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/575f58da5e304d8988302557bb345191.png)

### 9.ç³»ç»ŸåŠŸèƒ½å±•ç¤º

å›¾9.1.ç³»ç»Ÿæ”¯æŒæ£€æµ‹ç»“æœè¡¨æ ¼æ˜¾ç¤º

  å›¾9.2.ç³»ç»Ÿæ”¯æŒç½®ä¿¡åº¦å’ŒIOUé˜ˆå€¼æ‰‹åŠ¨è°ƒèŠ‚

  å›¾9.3.ç³»ç»Ÿæ”¯æŒè‡ªå®šä¹‰åŠ è½½æƒé‡æ–‡ä»¶best.pt(éœ€è¦ä½ é€šè¿‡æ­¥éª¤5ä¸­è®­ç»ƒè·å¾—)

  å›¾9.4.ç³»ç»Ÿæ”¯æŒæ‘„åƒå¤´å®æ—¶è¯†åˆ«

  å›¾9.5.ç³»ç»Ÿæ”¯æŒå›¾ç‰‡è¯†åˆ«

  å›¾9.6.ç³»ç»Ÿæ”¯æŒè§†é¢‘è¯†åˆ«

  å›¾9.7.ç³»ç»Ÿæ”¯æŒè¯†åˆ«ç»“æœæ–‡ä»¶è‡ªåŠ¨ä¿å­˜

  å›¾9.8.ç³»ç»Ÿæ”¯æŒExcelå¯¼å‡ºæ£€æµ‹ç»“æœæ•°æ®

![10.png](10.png)

![11.png](11.png)

![12.png](12.png)

![13.png](13.png)

![14.png](14.png)

![15.png](15.png)

![16.png](16.png)

![17.png](17.png)

### 10. YOLOv11æ ¸å¿ƒæ”¹è¿›æºç è®²è§£

#### 10.1 kan_conv.py

ä»¥ä¸‹æ˜¯å¯¹ä»£ç çš„æ ¸å¿ƒéƒ¨åˆ†è¿›è¡Œæç‚¼å’Œè¯¦ç»†æ³¨é‡Šçš„ç»“æœï¼š

```python
import torch
import torch.nn as nn

class KANConvNDLayer(nn.Module):
    def __init__(self, conv_class, norm_class, input_dim, output_dim, spline_order, kernel_size,
                 groups=1, padding=0, stride=1, dilation=1,
                 ndim: int = 2, grid_size=5, base_activation=nn.GELU, grid_range=[-1, 1], dropout=0.0):
        super(KANConvNDLayer, self).__init__()
        
        # åˆå§‹åŒ–å‚æ•°
        self.inputdim = input_dim  # è¾“å…¥ç»´åº¦
        self.outdim = output_dim    # è¾“å‡ºç»´åº¦
        self.spline_order = spline_order  # æ ·æ¡çš„é˜¶æ•°
        self.kernel_size = kernel_size  # å·ç§¯æ ¸å¤§å°
        self.padding = padding  # å¡«å……
        self.stride = stride  # æ­¥å¹…
        self.dilation = dilation  # è†¨èƒ€
        self.groups = groups  # åˆ†ç»„å·ç§¯çš„ç»„æ•°
        self.ndim = ndim  # æ•°æ®çš„ç»´åº¦ï¼ˆ1D, 2D, 3Dï¼‰
        self.grid_size = grid_size  # ç½‘æ ¼å¤§å°
        self.base_activation = base_activation()  # åŸºç¡€æ¿€æ´»å‡½æ•°
        self.grid_range = grid_range  # ç½‘æ ¼èŒƒå›´

        # åˆå§‹åŒ–dropoutå±‚
        self.dropout = nn.Dropout2d(p=dropout) if ndim == 2 else nn.Dropout3d(p=dropout) if ndim == 3 else nn.Dropout1d(p=dropout) if ndim == 1 else None
        
        # æ£€æŸ¥åˆ†ç»„å‚æ•°çš„æœ‰æ•ˆæ€§
        if groups <= 0:
            raise ValueError('groups must be a positive integer')
        if input_dim % groups != 0:
            raise ValueError('input_dim must be divisible by groups')
        if output_dim % groups != 0:
            raise ValueError('output_dim must be divisible by groups')

        # åˆ›å»ºåŸºç¡€å·ç§¯å±‚
        self.base_conv = nn.ModuleList([conv_class(input_dim // groups,
                                                   output_dim // groups,
                                                   kernel_size,
                                                   stride,
                                                   padding,
                                                   dilation,
                                                   groups=1,
                                                   bias=False) for _ in range(groups)])

        # åˆ›å»ºæ ·æ¡å·ç§¯å±‚
        self.spline_conv = nn.ModuleList([conv_class((grid_size + spline_order) * input_dim // groups,
                                                     output_dim // groups,
                                                     kernel_size,
                                                     stride,
                                                     padding,
                                                     dilation,
                                                     groups=1,
                                                     bias=False) for _ in range(groups)])

        # åˆ›å»ºå½’ä¸€åŒ–å±‚
        self.layer_norm = nn.ModuleList([norm_class(output_dim // groups) for _ in range(groups)])

        # åˆ›å»ºPReLUæ¿€æ´»å±‚
        self.prelus = nn.ModuleList([nn.PReLU() for _ in range(groups)])

        # åˆå§‹åŒ–ç½‘æ ¼
        h = (self.grid_range[1] - self.grid_range[0]) / grid_size
        self.grid = torch.linspace(
            self.grid_range[0] - h * spline_order,
            self.grid_range[1] + h * spline_order,
            grid_size + 2 * spline_order + 1,
            dtype=torch.float32
        )

        # ä½¿ç”¨Kaimingå‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–å·ç§¯å±‚æƒé‡
        for conv_layer in self.base_conv:
            nn.init.kaiming_uniform_(conv_layer.weight, nonlinearity='linear')

        for conv_layer in self.spline_conv:
            nn.init.kaiming_uniform_(conv_layer.weight, nonlinearity='linear')

    def forward_kan(self, x, group_index):
        # å¯¹è¾“å…¥åº”ç”¨åŸºç¡€æ¿€æ´»å‡½æ•°å¹¶è¿›è¡Œçº¿æ€§å˜æ¢
        base_output = self.base_conv[group_index](self.base_activation(x))

        # æ‰©å±•ç»´åº¦ä»¥è¿›è¡Œæ ·æ¡æ“ä½œ
        x_uns = x.unsqueeze(-1)  
        target = x.shape[1:] + self.grid.shape
        grid = self.grid.view(*list([1 for _ in range(self.ndim + 1)] + [-1, ])).expand(target).contiguous().to(x.device)

        # è®¡ç®—æ ·æ¡åŸº
        bases = ((x_uns >= grid[..., :-1]) & (x_uns < grid[..., 1:])).to(x.dtype)

        # è®¡ç®—å¤šé˜¶æ ·æ¡åŸº
        for k in range(1, self.spline_order + 1):
            left_intervals = grid[..., :-(k + 1)]
            right_intervals = grid[..., k:-1]
            delta = torch.where(right_intervals == left_intervals, torch.ones_like(right_intervals),
                                right_intervals - left_intervals)
            bases = ((x_uns - left_intervals) / delta * bases[..., :-1]) + \
                    ((grid[..., k + 1:] - x_uns) / (grid[..., k + 1:] - grid[..., 1:(-k)]) * bases[..., 1:])
        bases = bases.contiguous()
        bases = bases.moveaxis(-1, 2).flatten(1, 2)  # è°ƒæ•´ç»´åº¦ä»¥é€‚åº”å·ç§¯è¾“å…¥
        spline_output = self.spline_conv[group_index](bases)  # é€šè¿‡æ ·æ¡å·ç§¯å±‚
        x = self.prelus[group_index](self.layer_norm[group_index](base_output + spline_output))  # å½’ä¸€åŒ–å’Œæ¿€æ´»

        # åº”ç”¨dropout
        if self.dropout is not None:
            x = self.dropout(x)

        return x

    def forward(self, x):
        # å°†è¾“å…¥åˆ†å‰²ä¸ºå¤šä¸ªç»„
        split_x = torch.split(x, self.inputdim // self.groups, dim=1)
        output = []
        for group_ind, _x in enumerate(split_x):
            y = self.forward_kan(_x.clone(), group_ind)  # å¯¹æ¯ä¸ªç»„è¿›è¡Œå‰å‘ä¼ æ’­
            output.append(y.clone())
        y = torch.cat(output, dim=1)  # åˆå¹¶è¾“å‡º
        return y
```

### ä»£ç æ ¸å¿ƒéƒ¨åˆ†è¯´æ˜ï¼š
1. **KANConvNDLayerç±»**ï¼šè¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„Nç»´å·ç§¯å±‚ï¼Œæ”¯æŒ1Dã€2Då’Œ3Då·ç§¯ï¼Œä½¿ç”¨æ ·æ¡åŸºè¿›è¡Œå·ç§¯æ“ä½œã€‚
2. **åˆå§‹åŒ–æ–¹æ³•**ï¼šåˆå§‹åŒ–å·ç§¯å±‚ã€å½’ä¸€åŒ–å±‚ã€æ¿€æ´»å‡½æ•°å’Œdropoutå±‚ï¼Œå¹¶è¿›è¡Œå¿…è¦çš„å‚æ•°æ£€æŸ¥ã€‚
3. **forward_kanæ–¹æ³•**ï¼šå®ç°äº†å‰å‘ä¼ æ’­çš„å…·ä½“é€»è¾‘ï¼ŒåŒ…æ‹¬åŸºç¡€å·ç§¯ã€æ ·æ¡åŸºè®¡ç®—ã€æ ·æ¡å·ç§¯å’Œæœ€ç»ˆçš„æ¿€æ´»ä¸å½’ä¸€åŒ–ã€‚
4. **forwardæ–¹æ³•**ï¼šå°†è¾“å…¥æ•°æ®åˆ†å‰²ä¸ºå¤šä¸ªç»„ï¼Œå¹¶å¯¹æ¯ä¸ªç»„è°ƒç”¨`forward_kan`è¿›è¡Œå¤„ç†ï¼Œæœ€ååˆå¹¶è¾“å‡ºã€‚

é€šè¿‡ä»¥ä¸Šæ³¨é‡Šï¼Œå¯ä»¥æ›´æ¸…æ™°åœ°ç†è§£ä»£ç çš„ç»“æ„å’ŒåŠŸèƒ½ã€‚

è¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†ä¸€ä¸ªåä¸º `KANConvNDLayer` çš„ç¥ç»ç½‘ç»œå±‚ï¼Œæ—¨åœ¨å®ç°ä¸€ç§åŸºäºæ ·æ¡æ’å€¼çš„å·ç§¯æ“ä½œï¼Œæ”¯æŒå¤šç»´æ•°æ®ï¼ˆå¦‚1Dã€2Då’Œ3Dï¼‰ã€‚é¦–å…ˆï¼Œå¯¼å…¥äº† PyTorch çš„æ ¸å¿ƒåº“å’Œç¥ç»ç½‘ç»œæ¨¡å—ã€‚æ¥ç€ï¼Œ`KANConvNDLayer` ç±»ç»§æ‰¿è‡ª `nn.Module`ï¼Œåœ¨åˆå§‹åŒ–æ–¹æ³•ä¸­æ¥æ”¶å¤šä¸ªå‚æ•°ï¼ŒåŒ…æ‹¬å·ç§¯ç±»å‹ã€å½’ä¸€åŒ–ç±»å‹ã€è¾“å…¥å’Œè¾“å‡ºç»´åº¦ã€æ ·æ¡çš„é˜¶æ•°ã€å·ç§¯æ ¸å¤§å°ã€åˆ†ç»„æ•°ã€å¡«å……ã€æ­¥å¹…ã€æ‰©å¼ ç‡ã€ç»´åº¦æ•°é‡ã€ç½‘æ ¼å¤§å°ã€æ¿€æ´»å‡½æ•°ã€ç½‘æ ¼èŒƒå›´å’Œä¸¢å¼ƒç‡ã€‚

åœ¨åˆå§‹åŒ–è¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆè®¾ç½®äº†å„ä¸ªå‚æ•°ï¼Œå¹¶æ£€æŸ¥äº†åˆ†ç»„æ•°çš„æœ‰æ•ˆæ€§ã€‚æ¥ç€ï¼Œåˆ›å»ºäº†åŸºæœ¬å·ç§¯å±‚å’Œæ ·æ¡å·ç§¯å±‚çš„æ¨¡å—åˆ—è¡¨ï¼Œä½¿ç”¨æŒ‡å®šçš„å·ç§¯ç±»å’Œå½’ä¸€åŒ–ç±»è¿›è¡Œåˆå§‹åŒ–ã€‚è¿˜å®šä¹‰äº† PReLU æ¿€æ´»å‡½æ•°å’Œç½‘æ ¼ç”¨äºæ ·æ¡æ’å€¼çš„è®¡ç®—ã€‚æƒé‡åˆå§‹åŒ–é‡‡ç”¨ Kaiming å‡åŒ€åˆ†å¸ƒï¼Œä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°è®­ç»ƒã€‚

`forward_kan` æ–¹æ³•æ˜¯è¯¥ç±»çš„æ ¸å¿ƒï¼Œè´Ÿè´£æ‰§è¡Œå‰å‘ä¼ æ’­ã€‚å®ƒé¦–å…ˆå¯¹è¾“å…¥åº”ç”¨åŸºæœ¬æ¿€æ´»å‡½æ•°ï¼Œç„¶åé€šè¿‡åŸºæœ¬å·ç§¯å±‚è¿›è¡Œçº¿æ€§å˜æ¢ã€‚æ¥ç€ï¼Œè®¡ç®—æ ·æ¡åŸºå‡½æ•°ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™æ ·æ¡å·ç§¯å±‚ã€‚æœ€ç»ˆï¼Œè¾“å‡ºç»è¿‡å½’ä¸€åŒ–å’Œæ¿€æ´»å‡½æ•°å¤„ç†çš„ç»“æœï¼Œå¹¶æ ¹æ®éœ€è¦åº”ç”¨ä¸¢å¼ƒå±‚ã€‚

`forward` æ–¹æ³•å°†è¾“å…¥æŒ‰ç»„æ‹†åˆ†ï¼Œåˆ†åˆ«è°ƒç”¨ `forward_kan` æ–¹æ³•å¤„ç†æ¯ä¸ªç»„ï¼Œæœ€åå°†ç»“æœæ‹¼æ¥æˆä¸€ä¸ªå®Œæ•´çš„è¾“å‡ºã€‚

æ­¤å¤–ï¼Œæ–‡ä»¶ä¸­è¿˜å®šä¹‰äº†ä¸‰ä¸ªå­ç±» `KANConv3DLayer`ã€`KANConv2DLayer` å’Œ `KANConv1DLayer`ï¼Œåˆ†åˆ«ç”¨äºå¤„ç†ä¸‰ç»´ã€äºŒç»´å’Œä¸€ç»´æ•°æ®ã€‚è¿™äº›å­ç±»åœ¨åˆå§‹åŒ–æ—¶è°ƒç”¨çˆ¶ç±»çš„æ„é€ å‡½æ•°ï¼Œä¼ å…¥ç›¸åº”çš„å·ç§¯å’Œå½’ä¸€åŒ–ç±»å‹ã€‚

æ•´ä½“æ¥çœ‹ï¼Œè¿™ä¸ªæ–‡ä»¶å®ç°äº†ä¸€ç§çµæ´»çš„å·ç§¯å±‚ï¼Œèƒ½å¤Ÿå¤„ç†ä¸åŒç»´åº¦çš„æ•°æ®ï¼Œå¹¶ç»“åˆæ ·æ¡æ’å€¼çš„ç‰¹æ€§ï¼Œå¢å¼ºäº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚

#### 10.2 attention.py

ä»¥ä¸‹æ˜¯ä¿ç•™çš„æ ¸å¿ƒä»£ç éƒ¨åˆ†ï¼Œå¹¶æ·»åŠ äº†è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼š

```python
import torch
from torch import nn

class EMA(nn.Module):
    def __init__(self, channels, factor=8):
        super(EMA, self).__init__()
        self.groups = factor  # å°†é€šé“åˆ†æˆå¤šä¸ªç»„
        assert channels // self.groups > 0  # ç¡®ä¿æ¯ç»„è‡³å°‘æœ‰ä¸€ä¸ªé€šé“
        self.softmax = nn.Softmax(-1)  # ç”¨äºè®¡ç®—æƒé‡çš„softmax
        self.agp = nn.AdaptiveAvgPool2d((1, 1))  # è‡ªé€‚åº”å¹³å‡æ± åŒ–
        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))  # å¯¹é«˜åº¦è¿›è¡Œæ± åŒ–
        self.pool_w = nn.AdaptiveAvgPool2d((1, None))  # å¯¹å®½åº¦è¿›è¡Œæ± åŒ–
        self.gn = nn.GroupNorm(channels // self.groups, channels // self.groups)  # ç»„å½’ä¸€åŒ–
        self.conv1x1 = nn.Conv2d(channels // self.groups, channels // self.groups, kernel_size=1)  # 1x1å·ç§¯
        self.conv3x3 = nn.Conv2d(channels // self.groups, channels // self.groups, kernel_size=3, padding=1)  # 3x3å·ç§¯

    def forward(self, x):
        b, c, h, w = x.size()  # è·å–è¾“å…¥çš„æ‰¹é‡å¤§å°ã€é€šé“æ•°ã€é«˜åº¦å’Œå®½åº¦
        group_x = x.reshape(b * self.groups, -1, h, w)  # å°†è¾“å…¥é‡å¡‘ä¸º(b*g, c//g, h, w)
        x_h = self.pool_h(group_x)  # å¯¹é«˜åº¦è¿›è¡Œæ± åŒ–
        x_w = self.pool_w(group_x).permute(0, 1, 3, 2)  # å¯¹å®½åº¦è¿›è¡Œæ± åŒ–å¹¶è½¬ç½®
        hw = self.conv1x1(torch.cat([x_h, x_w], dim=2))  # 1x1å·ç§¯å¤„ç†
        x_h, x_w = torch.split(hw, [h, w], dim=2)  # å°†ç»“æœåˆ†å‰²ä¸ºé«˜åº¦å’Œå®½åº¦
        x1 = self.gn(group_x * x_h.sigmoid() * x_w.permute(0, 1, 3, 2).sigmoid())  # ç»„å½’ä¸€åŒ–
        x2 = self.conv3x3(group_x)  # 3x3å·ç§¯å¤„ç†
        x11 = self.softmax(self.agp(x1).reshape(b * self.groups, -1, 1).permute(0, 2, 1))  # è®¡ç®—æƒé‡
        x12 = x2.reshape(b * self.groups, c // self.groups, -1)  # é‡å¡‘
        x21 = self.softmax(self.agp(x2).reshape(b * self.groups, -1, 1).permute(0, 2, 1))  # è®¡ç®—æƒé‡
        x22 = x1.reshape(b * self.groups, c // self.groups, -1)  # é‡å¡‘
        weights = (torch.matmul(x11, x12) + torch.matmul(x21, x22)).reshape(b * self.groups, 1, h, w)  # è®¡ç®—æœ€ç»ˆæƒé‡
        return (group_x * weights.sigmoid()).reshape(b, c, h, w)  # è¿”å›åŠ æƒåçš„ç»“æœ

class SimAM(nn.Module):
    def __init__(self, e_lambda=1e-4):
        super(SimAM, self).__init__()
        self.activaton = nn.Sigmoid()  # æ¿€æ´»å‡½æ•°
        self.e_lambda = e_lambda  # æ­£åˆ™åŒ–å‚æ•°

    def forward(self, x):
        b, c, h, w = x.size()  # è·å–è¾“å…¥çš„æ‰¹é‡å¤§å°ã€é€šé“æ•°ã€é«˜åº¦å’Œå®½åº¦
        n = w * h - 1  # è®¡ç®—n
        x_minus_mu_square = (x - x.mean(dim=[2, 3], keepdim=True)).pow(2)  # è®¡ç®—å‡å€¼çš„å¹³æ–¹å·®
        y = x_minus_mu_square / (4 * (x_minus_mu_square.sum(dim=[2, 3], keepdim=True) / n + self.e_lambda)) + 0.5  # è®¡ç®—y
        return x * self.activaton(y)  # è¿”å›åŠ æƒåçš„ç»“æœ

class SpatialGroupEnhance(nn.Module):
    def __init__(self, groups=8):
        super().__init__()
        self.groups = groups  # ç»„æ•°
        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # è‡ªé€‚åº”å¹³å‡æ± åŒ–
        self.weight = nn.Parameter(torch.zeros(1, groups, 1, 1))  # æƒé‡å‚æ•°
        self.bias = nn.Parameter(torch.zeros(1, groups, 1, 1))  # åç½®å‚æ•°
        self.sig = nn.Sigmoid()  # Sigmoidæ¿€æ´»å‡½æ•°
        self.init_weights()  # åˆå§‹åŒ–æƒé‡

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out')  # Kaimingåˆå§‹åŒ–
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)  # åç½®åˆå§‹åŒ–ä¸º0
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)  # æ‰¹å½’ä¸€åŒ–æƒé‡åˆå§‹åŒ–ä¸º1
                nn.init.constant_(m.bias, 0)  # åç½®åˆå§‹åŒ–ä¸º0
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, std=0.001)  # çº¿æ€§å±‚æƒé‡åˆå§‹åŒ–
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)  # åç½®åˆå§‹åŒ–ä¸º0

    def forward(self, x):
        b, c, h, w = x.shape  # è·å–è¾“å…¥çš„æ‰¹é‡å¤§å°ã€é€šé“æ•°ã€é«˜åº¦å’Œå®½åº¦
        x = x.view(b * self.groups, -1, h, w)  # é‡å¡‘ä¸º(bs*g, dim//g, h, w)
        xn = x * self.avg_pool(x)  # è®¡ç®—å¹³å‡æ± åŒ–
        xn = xn.sum(dim=1, keepdim=True)  # å¯¹é€šé“ç»´åº¦æ±‚å’Œ
        t = xn.view(b * self.groups, -1)  # é‡å¡‘
        t = t - t.mean(dim=1, keepdim=True)  # å‡å»å‡å€¼
        std = t.std(dim=1, keepdim=True) + 1e-5  # è®¡ç®—æ ‡å‡†å·®
        t = t / std  # å½’ä¸€åŒ–
        t = t.view(b, self.groups, h, w)  # é‡å¡‘
        t = t * self.weight + self.bias  # è®¡ç®—æœ€ç»ˆæƒé‡
        t = t.view(b * self.groups, 1, h, w)  # é‡å¡‘
        x = x * self.sig(t)  # åŠ æƒ
        x = x.view(b, c, h, w)  # è¿”å›åŸå§‹å½¢çŠ¶
        return x
```

ä»¥ä¸Šä»£ç ä¿ç•™äº†ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š`EMA`ã€`SimAM` å’Œ `SpatialGroupEnhance`ï¼Œå¹¶ä¸ºæ¯ä¸ªæ¨¡å—æä¾›äº†è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼Œè§£é‡Šäº†æ¯ä¸ªéƒ¨åˆ†çš„åŠŸèƒ½å’Œä½œç”¨ã€‚

è¿™ä¸ªç¨‹åºæ–‡ä»¶ `attention.py` å®ç°äº†ä¸€ç³»åˆ—ä¸æ³¨æ„åŠ›æœºåˆ¶ç›¸å…³çš„æ¨¡å—ï¼Œä¸»è¦ç”¨äºæ·±åº¦å­¦ä¹ ä¸­çš„å›¾åƒå¤„ç†ä»»åŠ¡ã€‚æ–‡ä»¶ä¸­ä½¿ç”¨äº† PyTorch æ¡†æ¶ï¼ŒåŒ…å«äº†å¤šä¸ªç±»å’Œå‡½æ•°ï¼Œä¸‹é¢æ˜¯å¯¹ä¸»è¦éƒ¨åˆ†çš„è¯´æ˜ã€‚

é¦–å…ˆï¼Œæ–‡ä»¶å¯¼å…¥äº†å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬ PyTorchã€Torchvision å’Œä¸€äº›è‡ªå®šä¹‰æ¨¡å—ã€‚ç„¶åï¼Œå®šä¹‰äº†ä¸€äº›æ³¨æ„åŠ›æœºåˆ¶çš„ç±»ï¼Œå¦‚ `EMA`ã€`SimAM`ã€`SpatialGroupEnhance` ç­‰ã€‚æ¯ä¸ªç±»éƒ½ç»§æ‰¿è‡ª `nn.Module`ï¼Œå¹¶å®ç°äº† `__init__` å’Œ `forward` æ–¹æ³•ã€‚

`EMA` ç±»å®ç°äº†ä¸€ç§å¢å¼ºçš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡å¯¹è¾“å…¥è¿›è¡Œåˆ†ç»„å¤„ç†ï¼Œè®¡ç®—ä¸åŒç»„ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶é€šè¿‡å·ç§¯å’Œæ± åŒ–æ“ä½œç”Ÿæˆæƒé‡ï¼Œæœ€ç»ˆå¯¹è¾“å…¥è¿›è¡ŒåŠ æƒã€‚

`SimAM` ç±»å®ç°äº†ä¸€ç§ç®€å•çš„è‡ªé€‚åº”æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡è®¡ç®—è¾“å…¥çš„å‡å€¼å’Œæ–¹å·®ï¼Œç”Ÿæˆä¸€ä¸ªæ³¨æ„åŠ›æƒé‡ï¼Œå¹¶ä¸è¾“å…¥ç›¸ä¹˜ã€‚

`SpatialGroupEnhance` ç±»åˆ™é€šè¿‡å¯¹è¾“å…¥è¿›è¡Œç©ºé—´å¢å¼ºï¼Œåˆ©ç”¨è‡ªé€‚åº”å¹³å‡æ± åŒ–å’Œå·ç§¯æ“ä½œæ¥ç”Ÿæˆç©ºé—´æ³¨æ„åŠ›ã€‚

`TopkRouting` ç±»å®ç°äº†ä¸€ç§å¯å¾®åˆ†çš„ Top-k è·¯ç”±æœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®æŸ¥è¯¢å’Œé”®çš„ç›¸ä¼¼åº¦é€‰æ‹©å‰ k ä¸ªé‡è¦çš„é”®å€¼å¯¹ã€‚

`KVGather` ç±»ç”¨äºæ ¹æ®è·¯ç”±ç´¢å¼•é€‰æ‹©é”®å€¼å¯¹ï¼Œå¹¶æ”¯æŒä¸åŒçš„åŠ æƒæ–¹å¼ã€‚

`BiLevelRoutingAttention` ç±»å®ç°äº†åŒå±‚è·¯ç”±æ³¨æ„åŠ›æœºåˆ¶ï¼Œç»“åˆäº†å±€éƒ¨å’Œå…¨å±€æ³¨æ„åŠ›ï¼Œé€šè¿‡å¯¹è¾“å…¥è¿›è¡Œåˆ†å—å¤„ç†ï¼Œè®¡ç®—å„ä¸ªå—ä¹‹é—´çš„å…³ç³»ã€‚

æ­¤å¤–ï¼Œæ–‡ä»¶ä¸­è¿˜å®ç°äº†å¤šç§å…¶ä»–æ³¨æ„åŠ›æœºåˆ¶å’Œæ¨¡å—ï¼Œå¦‚ `CoordAtt`ã€`TripletAttention`ã€`BAMBlock`ã€`EfficientAttention` ç­‰ã€‚è¿™äº›æ¨¡å—é€šè¿‡ä¸åŒçš„æ–¹å¼å¯¹è¾“å…¥ç‰¹å¾è¿›è¡ŒåŠ æƒï¼Œå¢å¼ºæ¨¡å‹å¯¹é‡è¦ç‰¹å¾çš„å…³æ³¨ã€‚

åœ¨æ–‡ä»¶çš„æœ€åéƒ¨åˆ†ï¼Œå®šä¹‰äº†ä¸€äº›è¾…åŠ©å‡½æ•°å’Œç±»ï¼Œå¦‚ `img2windows` å’Œ `windows2img`ï¼Œç”¨äºå¤„ç†å›¾åƒçš„çª—å£åŒ–æ“ä½œï¼Œä»¥åŠä¸€äº›æ³¨æ„åŠ›æœºåˆ¶çš„å®ç°ç»†èŠ‚ã€‚

æ€»ä½“è€Œè¨€ï¼Œè¿™ä¸ªæ–‡ä»¶æä¾›äº†å¤šç§æ³¨æ„åŠ›æœºåˆ¶çš„å®ç°ï¼Œé€‚ç”¨äºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²ç­‰é¢†åŸŸã€‚é€šè¿‡ç»„åˆè¿™äº›æ¨¡å—ï¼Œå¯ä»¥æ„å»ºå‡ºæ›´ä¸ºå¤æ‚å’Œé«˜æ•ˆçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

#### 10.3 CTrans.py

ä»¥ä¸‹æ˜¯æå–å‡ºçš„æ ¸å¿ƒä»£ç éƒ¨åˆ†ï¼Œå¹¶é™„ä¸Šè¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼š

```python
import torch
import torch.nn as nn
import numpy as np
from torch.nn import Dropout, Softmax, Conv2d, LayerNorm

class Channel_Embeddings(nn.Module):
    """æ„å»ºæ¥è‡ªå›¾åƒå—å’Œä½ç½®çš„åµŒå…¥ã€‚"""
    def __init__(self, patchsize, img_size, in_channels):
        super().__init__()
        img_size = (img_size, img_size)  # å°†å›¾åƒå¤§å°è½¬æ¢ä¸ºå…ƒç»„
        patch_size = (patchsize, patchsize)  # å°†è¡¥ä¸å¤§å°è½¬æ¢ä¸ºå…ƒç»„
        n_patches = (img_size[0] // patch_size[0]) * (img_size[1] // patch_size[1])  # è®¡ç®—è¡¥ä¸æ•°é‡

        # ä½¿ç”¨æœ€å¤§æ± åŒ–å’Œå·ç§¯å±‚æ„å»ºè¡¥ä¸åµŒå…¥
        self.patch_embeddings = nn.Sequential(
            nn.MaxPool2d(kernel_size=5, stride=5),
            Conv2d(in_channels=in_channels,
                    out_channels=in_channels,
                    kernel_size=patchsize // 5,
                    stride=patchsize // 5)
        )

        # åˆå§‹åŒ–ä½ç½®åµŒå…¥
        self.position_embeddings = nn.Parameter(torch.zeros(1, n_patches, in_channels))
        self.dropout = Dropout(0.1)  # dropoutå±‚ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ

    def forward(self, x):
        """å‰å‘ä¼ æ’­å‡½æ•°ï¼Œè®¡ç®—åµŒå…¥ã€‚"""
        if x is None:
            return None
        x = self.patch_embeddings(x)  # è®¡ç®—è¡¥ä¸åµŒå…¥
        x = x.flatten(2)  # å°†å¼ é‡å±•å¹³
        x = x.transpose(-1, -2)  # è½¬ç½®å¼ é‡
        embeddings = x + self.position_embeddings  # åŠ ä¸Šä½ç½®åµŒå…¥
        embeddings = self.dropout(embeddings)  # åº”ç”¨dropout
        return embeddings

class Attention_org(nn.Module):
    """å®ç°å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€‚"""
    def __init__(self, vis, channel_num):
        super(Attention_org, self).__init__()
        self.vis = vis  # å¯è§†åŒ–æ ‡å¿—
        self.KV_size = sum(channel_num)  # é”®å€¼å¯¹çš„å¤§å°
        self.channel_num = channel_num  # é€šé“æ•°
        self.num_attention_heads = 4  # æ³¨æ„åŠ›å¤´çš„æ•°é‡

        # åˆå§‹åŒ–æŸ¥è¯¢ã€é”®ã€å€¼çš„çº¿æ€§å˜æ¢
        self.query = nn.ModuleList([nn.Linear(c, c, bias=False) for c in channel_num])
        self.key = nn.Linear(self.KV_size, self.KV_size, bias=False)
        self.value = nn.Linear(self.KV_size, self.KV_size, bias=False)
        self.softmax = Softmax(dim=3)  # softmaxå±‚
        self.attn_dropout = Dropout(0.1)  # æ³¨æ„åŠ›dropout
        self.proj_dropout = Dropout(0.1)  # æŠ•å½±dropout

    def forward(self, *embeddings):
        """å‰å‘ä¼ æ’­å‡½æ•°ï¼Œè®¡ç®—æ³¨æ„åŠ›è¾“å‡ºã€‚"""
        multi_head_Q = [query(emb) for query, emb in zip(self.query, embeddings) if emb is not None]
        multi_head_K = self.key(torch.cat(embeddings, dim=2))  # å°†æ‰€æœ‰åµŒå…¥æ‹¼æ¥å¹¶è®¡ç®—é”®
        multi_head_V = self.value(torch.cat(embeddings, dim=2))  # å°†æ‰€æœ‰åµŒå…¥æ‹¼æ¥å¹¶è®¡ç®—å€¼

        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        attention_scores = [torch.matmul(Q, multi_head_K) / np.sqrt(self.KV_size) for Q in multi_head_Q]
        attention_probs = [self.softmax(score) for score in attention_scores]  # è®¡ç®—æ³¨æ„åŠ›æ¦‚ç‡

        # åº”ç”¨dropout
        attention_probs = [self.attn_dropout(prob) for prob in attention_probs]
        context_layers = [torch.matmul(prob, multi_head_V) for prob in attention_probs]  # è®¡ç®—ä¸Šä¸‹æ–‡å±‚

        # çº¿æ€§å˜æ¢å’Œdropout
        outputs = [self.proj_dropout(layer) for layer in context_layers]
        return outputs

class Mlp(nn.Module):
    """å¤šå±‚æ„ŸçŸ¥æœºã€‚"""
    def __init__(self, in_channel, mlp_channel):
        super(Mlp, self).__init__()
        self.fc1 = nn.Linear(in_channel, mlp_channel)  # ç¬¬ä¸€å±‚çº¿æ€§å˜æ¢
        self.fc2 = nn.Linear(mlp_channel, in_channel)  # ç¬¬äºŒå±‚çº¿æ€§å˜æ¢
        self.act_fn = nn.GELU()  # æ¿€æ´»å‡½æ•°
        self.dropout = Dropout(0.0)  # dropoutå±‚

    def forward(self, x):
        """å‰å‘ä¼ æ’­å‡½æ•°ã€‚"""
        x = self.fc1(x)  # çº¿æ€§å˜æ¢
        x = self.act_fn(x)  # æ¿€æ´»
        x = self.dropout(x)  # åº”ç”¨dropout
        x = self.fc2(x)  # çº¿æ€§å˜æ¢
        return x

class ChannelTransformer(nn.Module):
    """é€šé“å˜æ¢å™¨ã€‚"""
    def __init__(self, channel_num=[64, 128, 256, 512], img_size=640, vis=False, patchSize=[40, 20, 10, 5]):
        super().__init__()
        self.embeddings = nn.ModuleList([Channel_Embeddings(patchSize[i], img_size // (2 ** (i + 2)), channel_num[i]) for i in range(len(channel_num))])
        self.encoder = Encoder(vis, channel_num)  # ç¼–ç å™¨
        self.reconstruct = nn.ModuleList([Reconstruct(channel_num[i], channel_num[i], kernel_size=1, scale_factor=(patchSize[i], patchSize[i])) for i in range(len(channel_num))])  # é‡æ„å±‚

    def forward(self, en):
        """å‰å‘ä¼ æ’­å‡½æ•°ã€‚"""
        embeddings = [emb(en[i]) for i, emb in enumerate(self.embeddings) if en[i] is not None]  # è®¡ç®—åµŒå…¥
        encoded = self.encoder(*embeddings)  # ç¼–ç 
        reconstructed = [recon(enc) + en[i] for i, (recon, enc) in enumerate(zip(self.reconstruct, encoded)) if en[i] is not None]  # é‡æ„
        return reconstructed  # è¿”å›é‡æ„ç»“æœ
```

### ä»£ç è¯´æ˜
1. **Channel_Embeddings**: è¯¥ç±»ç”¨äºå°†è¾“å…¥å›¾åƒåˆ†å‰²æˆå¤šä¸ªè¡¥ä¸ï¼Œå¹¶ä¸ºæ¯ä¸ªè¡¥ä¸æ·»åŠ ä½ç½®åµŒå…¥ã€‚å®ƒä½¿ç”¨å·ç§¯å’Œæœ€å¤§æ± åŒ–æ¥æå–ç‰¹å¾ã€‚

2. **Attention_org**: å®ç°äº†å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿå¤„ç†å¤šä¸ªè¾“å…¥åµŒå…¥ï¼Œè®¡ç®—æ³¨æ„åŠ›åˆ†æ•°å¹¶ç”Ÿæˆä¸Šä¸‹æ–‡å±‚ã€‚

3. **Mlp**: å®šä¹‰äº†ä¸€ä¸ªç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœºï¼ŒåŒ…å«ä¸¤ä¸ªçº¿æ€§å±‚å’Œä¸€ä¸ªæ¿€æ´»å‡½æ•°ã€‚

4. **ChannelTransformer**: è¯¥ç±»æ•´åˆäº†åµŒå…¥ã€ç¼–ç å’Œé‡æ„çš„è¿‡ç¨‹ï¼Œè´Ÿè´£æ•´ä¸ªæ¨¡å‹çš„å‰å‘ä¼ æ’­ã€‚å®ƒå°†è¾“å…¥å›¾åƒé€šè¿‡åµŒå…¥å±‚ã€ç¼–ç å™¨å’Œé‡æ„å±‚å¤„ç†ï¼Œæœ€ç»ˆè¿”å›é‡æ„åçš„ç»“æœã€‚

è¿™ä¸ªç¨‹åºæ–‡ä»¶ `CTrans.py` å®ç°äº†ä¸€ä¸ªåŸºäºé€šé“å˜æ¢å™¨ï¼ˆChannel Transformerï¼‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä¸»è¦ç”¨äºå›¾åƒå¤„ç†ä»»åŠ¡ã€‚è¯¥æ¨¡å‹çš„ç»“æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œä»¥ä¸‹æ˜¯å¯¹å„ä¸ªéƒ¨åˆ†çš„è¯¦ç»†è¯´æ˜ã€‚

é¦–å…ˆï¼Œæ–‡ä»¶å¯¼å…¥äº†ä¸€äº›å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬ `torch` å’Œ `torch.nn`ï¼Œè¿™äº›åº“æä¾›äº†æ„å»ºç¥ç»ç½‘ç»œæ‰€éœ€çš„åŸºç¡€ç»„ä»¶ã€‚æ¥ç€ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º `Channel_Embeddings` çš„ç±»ï¼Œè¯¥ç±»ç”¨äºæ„å»ºå›¾åƒçš„åµŒå…¥è¡¨ç¤ºã€‚å®ƒé€šè¿‡æœ€å¤§æ± åŒ–å’Œå·ç§¯æ“ä½œå°†è¾“å…¥å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªè¡¥ä¸ï¼Œå¹¶ä¸ºæ¯ä¸ªè¡¥ä¸ç”Ÿæˆä½ç½®åµŒå…¥ï¼Œæœ€åå°†è¡¥ä¸åµŒå…¥ä¸ä½ç½®åµŒå…¥ç›¸åŠ ï¼Œå¹¶åº”ç”¨ dropout ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

æ¥ä¸‹æ¥æ˜¯ `Reconstruct` ç±»ï¼Œå®ƒçš„ä½œç”¨æ˜¯é‡å»ºå›¾åƒã€‚è¯¥ç±»æ¥æ”¶ç»è¿‡å˜æ¢çš„åµŒå…¥ï¼Œåˆ©ç”¨å·ç§¯å±‚å’Œä¸Šé‡‡æ ·æ“ä½œå°†åµŒå…¥è½¬æ¢å›å›¾åƒç©ºé—´ï¼Œå¹¶é€šè¿‡æ‰¹å½’ä¸€åŒ–å’Œæ¿€æ´»å‡½æ•°è¿›è¡Œå¤„ç†ã€‚

`Attention_org` ç±»å®ç°äº†ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€‚å®ƒé€šè¿‡æŸ¥è¯¢ï¼ˆqueryï¼‰ã€é”®ï¼ˆkeyï¼‰å’Œå€¼ï¼ˆvalueï¼‰çŸ©é˜µæ¥è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ï¼Œå¹¶ä½¿ç”¨ softmax å‡½æ•°ç”Ÿæˆæ³¨æ„åŠ›æƒé‡ã€‚è¿™ä¸ªç±»æ”¯æŒå¤šä¸ªé€šé“çš„è¾“å…¥ï¼Œå¹¶é€šè¿‡ dropout æ¥æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚

`Mlp` ç±»å®šä¹‰äº†ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œç”¨äºåœ¨åµŒå…¥ç©ºé—´ä¸­è¿›è¡Œéçº¿æ€§å˜æ¢ã€‚å®ƒåŒ…å«ä¸¤ä¸ªå…¨è¿æ¥å±‚å’Œä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼ˆGELUï¼‰ï¼Œå¹¶åœ¨æ¯ä¸ªå±‚ååº”ç”¨ dropoutã€‚

`Block_ViT` ç±»æ˜¯ä¸€ä¸ªåŒ…å«æ³¨æ„åŠ›æœºåˆ¶å’Œå‰é¦ˆç½‘ç»œçš„æ¨¡å—ã€‚å®ƒé¦–å…ˆå¯¹è¾“å…¥çš„åµŒå…¥è¿›è¡Œå±‚å½’ä¸€åŒ–ï¼Œç„¶åé€šè¿‡æ³¨æ„åŠ›å±‚å’Œå‰é¦ˆç½‘ç»œè¿›è¡Œå¤„ç†ï¼Œæœ€åå°†ç»“æœä¸åŸå§‹è¾“å…¥ç›¸åŠ ï¼Œå½¢æˆæ®‹å·®è¿æ¥ã€‚

`Encoder` ç±»åˆ™ç”±å¤šä¸ª `Block_ViT` ç»„æˆï¼Œè´Ÿè´£å¯¹è¾“å…¥çš„åµŒå…¥è¿›è¡Œç¼–ç ã€‚å®ƒåœ¨æ¯ä¸ªå—ä¹‹ååº”ç”¨å±‚å½’ä¸€åŒ–ï¼Œå¹¶åœ¨éœ€è¦æ—¶è®°å½•æ³¨æ„åŠ›æƒé‡ã€‚

`ChannelTransformer` ç±»æ˜¯æ•´ä¸ªæ¨¡å‹çš„æ ¸å¿ƒï¼Œåˆå§‹åŒ–æ—¶æ¥æ”¶é€šé“æ•°ã€å›¾åƒå¤§å°ã€å¯è§†åŒ–æ ‡å¿—å’Œè¡¥ä¸å¤§å°ç­‰å‚æ•°ã€‚å®ƒåŒ…å«å¤šä¸ªåµŒå…¥å±‚ã€ç¼–ç å™¨å’Œé‡å»ºå±‚ã€‚æ¨¡å‹çš„å‰å‘ä¼ æ’­è¿‡ç¨‹åŒ…æ‹¬ç”ŸæˆåµŒå…¥ã€ç¼–ç ã€é‡å»ºå’ŒåŠ ä¸ŠåŸå§‹è¾“å…¥ï¼Œä»¥å®ç°å›¾åƒçš„å˜æ¢ã€‚

æœ€åï¼Œ`GetIndexOutput` ç±»ç”¨äºä»æ¨¡å‹çš„è¾“å‡ºä¸­æå–ç‰¹å®šç´¢å¼•çš„ç»“æœï¼Œä¾¿äºåç»­å¤„ç†ã€‚

æ€»ä½“è€Œè¨€ï¼Œè¿™ä¸ªç¨‹åºæ–‡ä»¶å®ç°äº†ä¸€ä¸ªå¤æ‚çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç»“åˆäº†é€šé“æ³¨æ„åŠ›æœºåˆ¶å’Œå¤šå±‚æ„ŸçŸ¥æœºï¼Œæ—¨åœ¨æé«˜å›¾åƒå¤„ç†ä»»åŠ¡çš„æ€§èƒ½ã€‚

#### 10.4 RFAConv.py

ä»¥ä¸‹æ˜¯ä»£ç ä¸­æœ€æ ¸å¿ƒçš„éƒ¨åˆ†ï¼Œå¹¶é™„ä¸Šè¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼š

```python
import torch
import torch.nn as nn
from einops import rearrange

class h_sigmoid(nn.Module):
    """å®ç°h-sigmoidæ¿€æ´»å‡½æ•°"""
    def __init__(self, inplace=True):
        super(h_sigmoid, self).__init__()
        self.relu = nn.ReLU6(inplace=inplace)  # ä½¿ç”¨ReLU6ä½œä¸ºåŸºç¡€

    def forward(self, x):
        return self.relu(x + 3) / 6  # h-sigmoidçš„å…¬å¼

class h_swish(nn.Module):
    """å®ç°h-swishæ¿€æ´»å‡½æ•°"""
    def __init__(self, inplace=True):
        super(h_swish, self).__init__()
        self.sigmoid = h_sigmoid(inplace=inplace)  # ä½¿ç”¨h-sigmoidä½œä¸ºåŸºç¡€

    def forward(self, x):
        return x * self.sigmoid(x)  # h-swishçš„å…¬å¼

class RFAConv(nn.Module):
    """å®ç°RFAConvæ¨¡å—"""
    def __init__(self, in_channel, out_channel, kernel_size, stride=1):
        super().__init__()
        self.kernel_size = kernel_size

        # æƒé‡ç”Ÿæˆæ¨¡å—
        self.get_weight = nn.Sequential(
            nn.AvgPool2d(kernel_size=kernel_size, padding=kernel_size // 2, stride=stride),
            nn.Conv2d(in_channel, in_channel * (kernel_size ** 2), kernel_size=1, groups=in_channel, bias=False)
        )
        
        # ç‰¹å¾ç”Ÿæˆæ¨¡å—
        self.generate_feature = nn.Sequential(
            nn.Conv2d(in_channel, in_channel * (kernel_size ** 2), kernel_size=kernel_size, padding=kernel_size // 2, stride=stride, groups=in_channel, bias=False),
            nn.BatchNorm2d(in_channel * (kernel_size ** 2)),
            nn.ReLU()
        )
        
        # æœ€ç»ˆå·ç§¯å±‚
        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=kernel_size)

    def forward(self, x):
        b, c = x.shape[0:2]  # è·å–è¾“å…¥çš„æ‰¹é‡å¤§å°å’Œé€šé“æ•°
        weight = self.get_weight(x)  # ç”Ÿæˆæƒé‡
        h, w = weight.shape[2:]  # è·å–ç‰¹å¾å›¾çš„é«˜å’Œå®½
        weighted = weight.view(b, c, self.kernel_size ** 2, h, w).softmax(2)  # å¯¹æƒé‡è¿›è¡Œsoftmaxå¤„ç†
        feature = self.generate_feature(x).view(b, c, self.kernel_size ** 2, h, w)  # ç”Ÿæˆç‰¹å¾
        weighted_data = feature * weighted  # åŠ æƒç‰¹å¾
        conv_data = rearrange(weighted_data, 'b c (n1 n2) h w -> b c (h n1) (w n2)', n1=self.kernel_size, n2=self.kernel_size)  # é‡æ’æ•°æ®
        return self.conv(conv_data)  # è¿”å›å·ç§¯ç»“æœ

class SE(nn.Module):
    """å®ç°Squeeze-and-Excitationæ¨¡å—"""
    def __init__(self, in_channel, ratio=16):
        super(SE, self).__init__()
        self.gap = nn.AdaptiveAvgPool2d((1, 1))  # å…¨å±€å¹³å‡æ± åŒ–
        self.fc = nn.Sequential(
            nn.Linear(in_channel, ratio, bias=False),  # å‹ç¼©é€šé“
            nn.ReLU(),
            nn.Linear(ratio, in_channel, bias=False),  # æ¢å¤é€šé“
            nn.Sigmoid()  # ä½¿ç”¨sigmoidæ¿€æ´»
        )

    def forward(self, x):
        b, c = x.shape[0:2]  # è·å–è¾“å…¥çš„æ‰¹é‡å¤§å°å’Œé€šé“æ•°
        y = self.gap(x).view(b, c)  # è¿›è¡Œå…¨å±€å¹³å‡æ± åŒ–å¹¶è°ƒæ•´å½¢çŠ¶
        y = self.fc(y).view(b, c, 1, 1)  # é€šè¿‡å…¨è¿æ¥å±‚
        return y  # è¿”å›é€šé“æ³¨æ„åŠ›

class RFCBAMConv(nn.Module):
    """å®ç°RFCBAMConvæ¨¡å—"""
    def __init__(self, in_channel, out_channel, kernel_size=3, stride=1):
        super().__init__()
        self.kernel_size = kernel_size
        self.generate = nn.Sequential(
            nn.Conv2d(in_channel, in_channel * (kernel_size ** 2), kernel_size, padding=kernel_size // 2, stride=stride, groups=in_channel, bias=False),
            nn.BatchNorm2d(in_channel * (kernel_size ** 2)),
            nn.ReLU()
        )
        self.get_weight = nn.Sequential(nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False), nn.Sigmoid())  # æƒé‡ç”Ÿæˆ
        self.se = SE(in_channel)  # Squeeze-and-Excitationæ¨¡å—
        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=kernel_size)  # æœ€ç»ˆå·ç§¯å±‚

    def forward(self, x):
        b, c = x.shape[0:2]  # è·å–è¾“å…¥çš„æ‰¹é‡å¤§å°å’Œé€šé“æ•°
        channel_attention = self.se(x)  # è®¡ç®—é€šé“æ³¨æ„åŠ›
        generate_feature = self.generate(x)  # ç”Ÿæˆç‰¹å¾

        h, w = generate_feature.shape[2:]  # è·å–ç‰¹å¾å›¾çš„é«˜å’Œå®½
        generate_feature = generate_feature.view(b, c, self.kernel_size ** 2, h, w)  # è°ƒæ•´å½¢çŠ¶
        
        generate_feature = rearrange(generate_feature, 'b c (n1 n2) h w -> b c (h n1) (w n2)', n1=self.kernel_size, n2=self.kernel_size)  # é‡æ’æ•°æ®
        
        unfold_feature = generate_feature * channel_attention  # åŠ æƒç‰¹å¾
        max_feature, _ = torch.max(generate_feature, dim=1, keepdim=True)  # æœ€å¤§ç‰¹å¾
        mean_feature = torch.mean(generate_feature, dim=1, keepdim=True)  # å¹³å‡ç‰¹å¾
        receptive_field_attention = self.get_weight(torch.cat((max_feature, mean_feature), dim=1))  # æ„Ÿå—é‡æ³¨æ„åŠ›
        conv_data = unfold_feature * receptive_field_attention  # åŠ æƒåçš„ç‰¹å¾
        return self.conv(conv_data)  # è¿”å›å·ç§¯ç»“æœ

class RFCAConv(nn.Module):
    """å®ç°RFCAConvæ¨¡å—"""
    def __init__(self, inp, oup, kernel_size, stride=1, reduction=32):
        super(RFCAConv, self).__init__()
        self.kernel_size = kernel_size
        self.generate = nn.Sequential(
            nn.Conv2d(inp, inp * (kernel_size ** 2), kernel_size, padding=kernel_size // 2, stride=stride, groups=inp, bias=False),
            nn.BatchNorm2d(inp * (kernel_size ** 2)),
            nn.ReLU()
        )
        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))  # è‡ªé€‚åº”å¹³å‡æ± åŒ–ï¼ˆé«˜åº¦ï¼‰
        self.pool_w = nn.AdaptiveAvgPool2d((1, None))  # è‡ªé€‚åº”å¹³å‡æ± åŒ–ï¼ˆå®½åº¦ï¼‰

        mip = max(8, inp // reduction)  # ä¸­é—´é€šé“æ•°

        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)  # 1x1å·ç§¯
        self.bn1 = nn.BatchNorm2d(mip)  # æ‰¹å½’ä¸€åŒ–
        self.act = h_swish()  # h-swishæ¿€æ´»å‡½æ•°
        
        self.conv_h = nn.Conv2d(mip, inp, kernel_size=1, stride=1, padding=0)  # é«˜åº¦å·ç§¯
        self.conv_w = nn.Conv2d(mip, inp, kernel_size=1, stride=1, padding=0)  # å®½åº¦å·ç§¯
        self.conv = nn.Conv2d(inp, oup, kernel_size, stride=kernel_size)  # æœ€ç»ˆå·ç§¯å±‚

    def forward(self, x):
        b, c = x.shape[0:2]  # è·å–è¾“å…¥çš„æ‰¹é‡å¤§å°å’Œé€šé“æ•°
        generate_feature = self.generate(x)  # ç”Ÿæˆç‰¹å¾
        h, w = generate_feature.shape[2:]  # è·å–ç‰¹å¾å›¾çš„é«˜å’Œå®½
        generate_feature = generate_feature.view(b, c, self.kernel_size ** 2, h, w)  # è°ƒæ•´å½¢çŠ¶
        
        generate_feature = rearrange(generate_feature, 'b c (n1 n2) h w -> b c (h n1) (w n2)', n1=self.kernel_size, n2=self.kernel_size)  # é‡æ’æ•°æ®
        
        x_h = self.pool_h(generate_feature)  # é«˜åº¦æ± åŒ–
        x_w = self.pool_w(generate_feature).permute(0, 1, 3, 2)  # å®½åº¦æ± åŒ–å¹¶è°ƒæ•´ç»´åº¦

        y = torch.cat([x_h, x_w], dim=2)  # åˆå¹¶æ± åŒ–ç»“æœ
        y = self.conv1(y)  # é€šè¿‡1x1å·ç§¯
        y = self.bn1(y)  # æ‰¹å½’ä¸€åŒ–
        y = self.act(y)  # æ¿€æ´»
        
        h, w = generate_feature.shape[2:]  # è·å–ç‰¹å¾å›¾çš„é«˜å’Œå®½
        x_h, x_w = torch.split(y, [h, w], dim=2)  # åˆ†å‰²æ± åŒ–ç»“æœ
        x_w = x_w.permute(0, 1, 3, 2)  # è°ƒæ•´ç»´åº¦

        a_h = self.conv_h(x_h).sigmoid()  # é«˜åº¦æ³¨æ„åŠ›
        a_w = self.conv_w(x_w).sigmoid()  # å®½åº¦æ³¨æ„åŠ›
        return self.conv(generate_feature * a_w * a_h)  # è¿”å›åŠ æƒåçš„å·ç§¯ç»“æœ
```

### ä»£ç è¯´æ˜
1. **æ¿€æ´»å‡½æ•°**:
   - `h_sigmoid` å’Œ `h_swish` æ˜¯è‡ªå®šä¹‰çš„æ¿€æ´»å‡½æ•°ï¼Œåˆ†åˆ«å®ç°äº† h-sigmoid å’Œ h-swishã€‚

2. **RFAConv**:
   - è¯¥æ¨¡å—é€šè¿‡ç”Ÿæˆç‰¹å¾å’Œæƒé‡æ¥å®ç°åŠ æƒå·ç§¯ï¼Œåˆ©ç”¨äº†è‡ªé€‚åº”çš„æƒé‡ç”Ÿæˆæœºåˆ¶ã€‚

3. **SE (Squeeze-and-Excitation)**:
   - è¯¥æ¨¡å—é€šè¿‡å…¨å±€å¹³å‡æ± åŒ–å’Œå…¨è¿æ¥å±‚å®ç°é€šé“æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¢å¼ºäº†ç½‘ç»œå¯¹é‡è¦ç‰¹å¾çš„å…³æ³¨ã€‚

4. **RFCBAMConv**:
   - è¯¥æ¨¡å—ç»“åˆäº†é€šé“æ³¨æ„åŠ›å’Œæ„Ÿå—é‡æ³¨æ„åŠ›ï¼Œè¿›ä¸€æ­¥æå‡äº†ç‰¹å¾æå–çš„èƒ½åŠ›ã€‚

5. **RFCAConv**:
   - è¯¥æ¨¡å—é€šè¿‡é«˜åº¦å’Œå®½åº¦çš„è‡ªé€‚åº”æ± åŒ–æ¥ç”Ÿæˆç‰¹å¾ï¼Œå¹¶ç»“åˆæ³¨æ„åŠ›æœºåˆ¶æ¥ä¼˜åŒ–å·ç§¯ç»“æœã€‚

è¿™äº›æ¨¡å—å¯ä»¥åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ç”¨ä½œç‰¹å¾æå–å’Œå¢å¼ºçš„ç»„ä»¶ï¼Œæå‡æ¨¡å‹çš„æ€§èƒ½ã€‚

è¿™ä¸ªç¨‹åºæ–‡ä»¶ `RFAConv.py` å®šä¹‰äº†ä¸€äº›ç”¨äºå·ç§¯ç¥ç»ç½‘ç»œçš„æ¨¡å—ï¼Œä¸»è¦åŒ…æ‹¬ RFAConvã€RFCBAMConv å’Œ RFCAConvã€‚è¿™äº›æ¨¡å—é€šè¿‡ä¸åŒçš„æ–¹å¼å®ç°äº†ç‰¹å¾æå–å’Œé€šé“æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥å¢å¼ºç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›ã€‚

é¦–å…ˆï¼Œæ–‡ä»¶ä¸­å¼•å…¥äº†å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬ PyTorch å’Œä¸€äº›è‡ªå®šä¹‰çš„å·ç§¯æ¨¡å—ã€‚æ¥ç€ï¼Œå®šä¹‰äº†ä¸¤ä¸ªæ¿€æ´»å‡½æ•°ç±» `h_sigmoid` å’Œ `h_swish`ï¼Œå®ƒä»¬åˆ†åˆ«å®ç°äº†ç¡¬ sigmoid å’Œç¡¬ swish æ¿€æ´»å‡½æ•°ã€‚è¿™äº›æ¿€æ´»å‡½æ•°åœ¨æ·±åº¦å­¦ä¹ ä¸­ç”¨äºå¼•å…¥éçº¿æ€§ç‰¹æ€§ã€‚

æ¥ä¸‹æ¥æ˜¯ `RFAConv` ç±»çš„å®šä¹‰ã€‚è¿™ä¸ªç±»çš„æ„é€ å‡½æ•°æ¥æ”¶è¾“å…¥é€šé“æ•°ã€è¾“å‡ºé€šé“æ•°ã€å·ç§¯æ ¸å¤§å°å’Œæ­¥å¹…ã€‚å®ƒå†…éƒ¨å®šä¹‰äº†ä¸¤ä¸ªä¸»è¦çš„æ“ä½œï¼š`get_weight` å’Œ `generate_feature`ã€‚`get_weight` é€šè¿‡å¹³å‡æ± åŒ–å’Œå·ç§¯æ“ä½œç”Ÿæˆæƒé‡ï¼Œè€Œ `generate_feature` åˆ™ç”¨äºç”Ÿæˆç‰¹å¾å›¾ã€‚`forward` æ–¹æ³•ä¸­ï¼Œè¾“å…¥æ•°æ®ç»è¿‡è¿™ä¸¤ä¸ªæ“ä½œåï¼Œç”Ÿæˆçš„ç‰¹å¾å›¾ä¸æƒé‡ç›¸ä¹˜ï¼Œæœ€åé€šè¿‡å·ç§¯å±‚è¾“å‡ºç»“æœã€‚

`SE` ç±»å®ç°äº† Squeeze-and-Excitation æ¨¡å—ï¼Œç”¨äºå¢å¼ºé€šé“é—´çš„å…³ç³»ã€‚å®ƒé€šè¿‡å…¨å±€å¹³å‡æ± åŒ–å’Œå…¨è¿æ¥å±‚æ¥è®¡ç®—é€šé“æ³¨æ„åŠ›ï¼Œå¹¶å°†å…¶åº”ç”¨äºè¾“å…¥ç‰¹å¾å›¾ã€‚

`RFCBAMConv` ç±»æ˜¯ä¸€ä¸ªç»“åˆäº† RFAConv å’Œ SE æ¨¡å—çš„å¤åˆæ¨¡å—ã€‚å®ƒåœ¨æ„é€ å‡½æ•°ä¸­å®šä¹‰äº†ç‰¹å¾ç”Ÿæˆå’Œæƒé‡è·å–çš„è¿‡ç¨‹ï¼Œå¹¶åœ¨ `forward` æ–¹æ³•ä¸­å°†é€šé“æ³¨æ„åŠ›ä¸ç”Ÿæˆçš„ç‰¹å¾ç»“åˆï¼Œæœ€ç»ˆé€šè¿‡å·ç§¯å±‚è¾“å‡ºç»“æœã€‚

æœ€åï¼Œ`RFCAConv` ç±»å®ç°äº†ä¸€ä¸ªæ›´å¤æ‚çš„å·ç§¯æ¨¡å—ï¼Œç»“åˆäº†ç©ºé—´å’Œé€šé“æ³¨æ„åŠ›æœºåˆ¶ã€‚å®ƒé€šè¿‡ç”Ÿæˆç‰¹å¾å›¾ã€æ± åŒ–æ“ä½œå’Œå·ç§¯å±‚æ¥è®¡ç®—æ³¨æ„åŠ›ï¼Œå¹¶å°†ç»“æœåº”ç”¨äºè¾“å…¥ç‰¹å¾å›¾ã€‚è¯¥æ¨¡å—çš„è®¾è®¡æ—¨åœ¨æé«˜ç½‘ç»œå¯¹ä¸åŒç©ºé—´å’Œé€šé“ç‰¹å¾çš„æ•æ„Ÿæ€§ã€‚

æ€»ä½“æ¥è¯´ï¼Œè¿™ä¸ªæ–‡ä»¶ä¸­çš„æ¨¡å—é€šè¿‡ä¸åŒçš„å·ç§¯å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ—¨åœ¨æå‡å·ç§¯ç¥ç»ç½‘ç»œåœ¨å›¾åƒå¤„ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ç‰¹å¾æå–å’Œé€šé“å…³ç³»å»ºæ¨¡æ–¹é¢ã€‚

### 11.å®Œæ•´è®­ç»ƒ+Webå‰ç«¯ç•Œé¢+200+ç§å…¨å¥—åˆ›æ–°ç‚¹æºç ã€æ•°æ®é›†è·å–

![19.png](19.png)


# [ä¸‹è½½é“¾æ¥ï¼šhttps://mbd.pub/o/bread/Z5yblJlw](https://mbd.pub/o/bread/Z5yblJlw)